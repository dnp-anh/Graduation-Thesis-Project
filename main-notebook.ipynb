{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Explainable Deep Multi-branch Neural Network for Recognizing Autonomic Activation States from Multimodal Physiological Signals**\n\n## Introduction\nThis notebook presents the **experimental pipeline** used in the thesis, including:\n- Data preprocessing and feature engineering  \n- Model construction and training (Hybrid model and baseline models)  \n- Performance evaluation using multiple metrics (accuracy, F1-score, confusion matrix, etc.)  \n- Model explainability analysis with attention weights (mean activation, temporal attention, entropy)\n\n## Objective\nThe objectives of this notebook are:\n1. To demonstrate the complete experimental process from raw data to final results.  \n2. To compare the performance of the proposed Hybrid model with baseline models (both Machine Learning and Deep Learning).  \n3. To provide a reproducible workflow that supports validation and further research.","metadata":{}},{"cell_type":"markdown","source":"## Import Required Libraries\n\nBefore running the experiments, some Python packages need to be installed (if not already available in the environment).\nThe following packages are required in addition to standard ML/DL libraries:\n\n- **peakutils**: for signal peak detection and processing  \n- **biosppy**: for biomedical signal processing (e.g., ECG, respiration)  \n- **tsaug**: for time-series data augmentation  ","metadata":{}},{"cell_type":"code","source":"!pip install peakutils","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install biosppy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install tsaug","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# üìÇ Data Handling & Preprocessing\n# ============================================================\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom scipy import stats\n\n# ============================================================\n# üìÇ Signal Processing\n# ============================================================\nfrom scipy import signal, interpolate\nfrom scipy.signal import (\n    find_peaks, butter, filtfilt, detrend, resample\n)\nfrom scipy.ndimage import uniform_filter1d\nfrom scipy.interpolate import interp1d\nfrom scipy.optimize import minimize\nfrom scipy.stats import skew, kurtosis\n\nimport pywt  # Wavelet transform\n\n# Biosppy: specialized functions for biomedical signals\nfrom biosppy.signals import resp as biosppy_resp\nfrom biosppy.signals import eda as biosppy_eda\nfrom biosppy.signals import ecg as biosppy_ecg\n\n# Tsaug: data augmentation for time-series\nfrom tsaug import TimeWarp, Drift, AddNoise\n\n# ============================================================\n# üìÇ Visualization & Analysis\n# ============================================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\n# ============================================================\n# üìÇ Model Saving / Loading & Utilities\n# ============================================================\nimport pickle\nimport joblib\nimport os\nfrom tqdm import tqdm\n\n# ============================================================\n# üìÇ Deep Learning (TensorFlow / Keras)\n# ============================================================\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Dense, Dropout, Conv1D, MaxPooling1D, GRU, Bidirectional,\n    GlobalAveragePooling1D, Add, MultiHeadAttention, Concatenate, \n    BatchNormalization, ReLU, Multiply, Activation, LayerNormalization, ELU\n)\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import (\n    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n)\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.activations import relu  # Explicit ReLU activation\n\n# ============================================================\n# üìÇ Classical Machine Learning Models (Baselines)\n# ============================================================\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\n# ============================================================\n# üìÇ Model Evaluation\n# ============================================================\nfrom sklearn.metrics import (\n    accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \n    classification_report, roc_auc_score, roc_curve, auc, f1_score)\n\n# ============================================================\n# üìÇ Model Selection & Cross-validation\n# ============================================================\nfrom sklearn.model_selection import KFold\n\n# ============================================================\n# üìÇ Additional\n# ============================================================\nfrom sklearn.preprocessing import label_binarize\nfrom collections import defaultdict\n\n# ============================================================\n# üìÇ Warning Control\n# ============================================================\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"‚úîÔ∏è All libraries imported successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convert & Merge (WESAD Dataset)\n\nIn this section, raw WESAD data files in pickle format (`.pkl`) are converted into a unified DataFrame structure. \nThe process includes:\n\n1. **Configuration**  \n   - Define input/output paths.  \n   - Specify subject IDs (excluding S12, due to corrupted data).  \n   - Select physiological signals of interest: **ECG**, **EDA**, and **Respiration**.  \n\n2. **Conversion**  \n   - Each subject's pickle file contains multiple signals.  \n   - Signals from the chest device (ECG, EDA, Resp) are extracted.  \n   - Labels are aligned with signals and a subject ID (`sid`) column is added.  \n\n3. **Merging**  \n   - Data from all subjects are concatenated into one large DataFrame.  \n   - Columns: `['sid', 'ecg', 'eda', 'resp', 'label']`.  \n\n4. **Filtering**  \n   - Only keep the relevant labels: **Baseline (1)**, **Stress (2)**, and **Amusement (3)**.  \n   - Relabel them as `{0: Baseline, 1: Stress, 2: Amusement}` for supervised learning.  \n\n5. **Saving**  \n   - Save both raw merged data (`merged_chest.pkl`) and filtered data (`merged_chest_fltr.pkl`) for reproducibility.  ","metadata":{}},{"cell_type":"code","source":"# ==== Step 1. Basic Configuration ====\nWESAD_PATH = '/kaggle/input/wesad-dataset/WESAD'\nOUTPUT_PATH = '/kaggle/working/wesad_processed'\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\n# Subject IDs (2‚Äì17, excluding 12 because of missing/corrupted data)\nids = [i for i in range(2, 18) if i != 12]\n\n# Columns used for chest signals\ncols_chest = ['sid', 'ecg', 'eda', 'resp', 'label']\nsf_chest = 700  # Sampling frequency\n\nprint(\"‚úîÔ∏è Configuration done.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Step 2. Convert from Pickle to DataFrame ====\ndef pkl_to_chest(filename, sub_id):\n    \"\"\"\n    Convert raw pickle dictionary for a subject into a NumPy array.\n\n    Parameters:\n        filename (str): Path to pickle file for a subject.\n        sub_id (int): Subject ID.\n\n    Returns:\n        np.array: Chest data [sid, ecg, eda, resp, label].\n    \"\"\"\n    unpickled_df = pd.read_pickle(filename)\n\n    chest_ecg = unpickled_df['signal']['chest']['ECG'][:, 0].reshape(-1, 1)\n    chest_eda = unpickled_df['signal']['chest']['EDA'].reshape(-1, 1)\n    chest_resp = unpickled_df['signal']['chest']['Resp'].reshape(-1, 1)\n\n    label = unpickled_df['label'].reshape(-1, 1)\n    sid = np.full((label.shape[0], 1), sub_id)\n\n    chest_data = np.concatenate((sid, chest_ecg, chest_eda, chest_resp, label), axis=1)\n    return chest_data\n\n\n# ==== Step 3. Merge multiple subjects ====\ndef merge_chest(ids):\n    merged_data = np.empty((0, len(cols_chest)))\n\n    for sid in ids:\n        file_path = os.path.join(WESAD_PATH, f'S{sid}', f'S{sid}.pkl')\n        print(f\"\\nProcessing subject: S{sid}\")\n\n        if os.path.exists(file_path):\n            subject_data = pkl_to_chest(file_path, sid)\n            merged_data = np.concatenate((merged_data, subject_data), axis=0)\n            print(f\"Merged shape so far: {merged_data.shape}\")\n        else:\n            print(f\"‚ùå File not found: {file_path}\")\n\n    # Convert to DataFrame with proper types\n    merged_df = pd.DataFrame(merged_data, columns=cols_chest).astype({\n        'sid': int, 'ecg': float, 'eda': float, 'resp': float, 'label': int\n    })\n\n    # Save merged DataFrame\n    merged_df.to_pickle(os.path.join(OUTPUT_PATH, 'merged_chest.pkl'))\n    print(f\"\\n‚úîÔ∏è Merged dataset saved at {OUTPUT_PATH}/merged_chest.pkl\")\n\n\n# ==== Step 4. Filter relevant labels ====\ndef filter_chest_data():\n    \"\"\"\n    Keep only baseline, stress, and amusement classes.\n    Map labels {1:0, 2:1, 3:2}.\n    \"\"\"\n    df = pd.read_pickle(os.path.join(OUTPUT_PATH, \"merged_chest.pkl\"))\n    df_fltr = df[df[\"label\"].isin([1, 2, 3])]\n    label_map = {1: 0, 2: 1, 3: 2}\n    df_fltr['label'] = df_fltr['label'].map(label_map)\n\n    print(f\"Filtered dataset shape: {df_fltr.shape}\")\n    df_fltr.to_pickle(os.path.join(OUTPUT_PATH, \"merged_chest_fltr.pkl\"))\n    print(f\"‚úîÔ∏è Filtered dataset saved at {OUTPUT_PATH}/merged_chest_fltr.pkl\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==== Step 5. Run Preprocessing Pipeline ====\ndef preprocess():\n    merge_chest(ids)\n    filter_chest_data()\n\npreprocess()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)\n\nIn this section, the filtered WESAD dataset (`merged_chest_fltr.pkl`) is loaded and inspected to ensure data quality before preprocessing. The process includes:\n\n1. **Loading & Inspection**\n   - Load the filtered dataset from disk.\n   - Display dataset shape, first rows (`head()`), and basic info (`info()`).\n   - Summarize descriptive statistics (`describe()`).\n   - Check unique subject IDs and label distribution per subject.\n\n2. **Label Distribution**\n   - Visualize the number of samples for each condition:\n     - **Baseline (0)**\n     - **Stress (1)**\n     - **Amusement (2)**\n\n3. **Signal Preview**\n   - Plot the first 10 seconds of physiological signals to verify signal quality.\n   - Signals inspected:\n     - **ECG** (Electrocardiogram ‚Äì heart electrical activity).\n     - **EDA** (Electrodermal Activity ‚Äì skin conductance, related to arousal).\n     - **Resp** (Respiration ‚Äì breathing patterns).\n\n4. **Purpose**\n   - Ensure that the dataset is correctly filtered and structured.\n   - Identify potential class imbalance in labels.\n   - Visually confirm that physiological signals are properly recorded.","metadata":{}},{"cell_type":"code","source":"fltr_data = pd.read_pickle(os.path.join(OUTPUT_PATH, \"merged_chest_fltr.pkl\"))\nprint(f\"Filtered Data Shape: {fltr_data.shape}\")\nfltr_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fltr_data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fltr_data.describe().T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(fltr_data['sid'].unique())\nfltr_data.groupby(['sid', 'label']).head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nax = sns.countplot(\n    data=fltr_data,\n    x=\"label\",\n    hue=\"label\",\n    dodge=False\n)\nax.legend_.remove()\nplt.xticks([0, 1, 2], [\"Baseline\", \"Stressed\", \"Amusement\"])\nplt.title(\"Number of Baseline, Stressed and Amusement Data Points\")\nplt.xlabel(\"Condition\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampling_rate = sf_chest  # Hz\nduration_sec = 10\nsamples_to_plot = sampling_rate * duration_sec\necg_raw=fltr_data['ecg']\necg_signal=ecg_raw\n\n# --- Time axis ---\ntime_axis = np.linspace(0, duration_sec, samples_to_plot)\n\n# --- Plot ECG ---\nplt.figure(figsize=(15, 4))\nplt.plot(time_axis, ecg_signal[:samples_to_plot])\nplt.title('ecg first 5 sec')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampling_rate = sf_chest  # Hz\nduration_sec = 10\nsamples_to_plot = sampling_rate * duration_sec\neda_raw=fltr_data['eda']\neda_signal=eda_raw\n\n# --- Time axis ---\ntime_axis = np.linspace(0, duration_sec, samples_to_plot)\n\n# --- Plot EDA ---\nplt.figure(figsize=(15, 4))\nplt.plot(time_axis, eda_signal[:samples_to_plot])\nplt.title('eda first 5 sec')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampling_rate = sf_chest  # Hz\nduration_sec = 10\nsamples_to_plot = sampling_rate * duration_sec\nresp_raw=fltr_data['resp']\nresp_signal=resp_raw\n\n# --- Time axis ---\ntime_axis = np.linspace(0, duration_sec, samples_to_plot)\n\n# --- Plot RESP ---\nplt.figure(figsize=(15, 4))\nplt.plot(time_axis, resp_signal[:samples_to_plot])\nplt.title('resp first 5 sec')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing  \n\nThis section describes the **preprocessing pipeline** applied to the physiological signals (ECG, EDA, RESP) for stress detection.  \nThe pipeline includes:  \n\n1. **Signal filtering & denoising**  \n   - ECG, EDA, and RESP signals are filtered using either `biosppy` functions or custom filters.  \n   - Alternative denoising methods (e.g., wavelet, detrending) are also available if `use_biosppy=False`.  \n\n2. **Normalization**  \n   - ECG and RESP signals are standardized (`StandardScaler`).  \n   - EDA signals are scaled to `[0, 1]` range using `MinMaxScaler`.  \n\n3. **Segmentation**  \n   - Continuous labeled signals are split into windows of fixed length (e.g., 30 seconds).  \n   - Overlapping windows are generated with a defined stride (e.g., 5 seconds).  \n   - Very short segments are discarded.  \n\n4. **Downsampling**  \n   - Each window is downsampled to a fixed length (`target_len=3500`) to ensure uniform input size across subjects and modalities.  \n\n5. **Data aggregation**  \n   - Segments are collected from all subjects.  \n   - Only valid samples (with consistent shapes) are kept.  \n   - Final output includes preprocessed ECG, EDA, RESP arrays, labels, subject IDs, and sample IDs.\n\n6. **Feature extraction for machine learning**\n   - For **ECG**, HRV-based features are extracted: mean RR interval, SDNN, RMSSD, NN50, pNN50.\n   - For **EDA**, statistical and dynamic features are extracted: mean, standard deviation, max, min, mean/SD of differences, signal power.\n   - For **RESP**, respiratory features are extracted: mean, standard deviation, max, min, and estimated breath rate.\n   - Features from all modalities are concatenated into a single feature vector per segment, producing a final feature matrix suitable for classical ML models.","metadata":{}},{"cell_type":"code","source":"# ===== ECG Preprocessing =====\ndef preprocess_ecg_raw(ecg_signal, fs=sf_chest, target_len=None, use_biosppy=True):\n    if use_biosppy:\n        ecg_processed = biosppy_ecg.ecg(signal=ecg_signal, sampling_rate=fs, show=False)\n        filtered = ecg_processed['filtered']\n    else:\n        filtered = highpass_filter(ecg_signal, cutoff=0.5, fs=fs)\n        filtered = wavelet_denoise(filtered)\n\n    # Adjust signal length if target length is specified\n    if target_len is not None:\n        if len(filtered) > target_len:\n            filtered = filtered[:target_len]\n        elif len(filtered) < target_len:\n            filtered = np.pad(filtered, (0, target_len - len(filtered)), mode='constant')\n    return filtered\n\n\n# ===== EDA Preprocessing =====\ndef preprocess_eda_raw(eda_signal_raw, fs=sf_chest, target_len=None, use_biosppy=True):\n    if use_biosppy:\n        eda_processed = biosppy_eda.eda(signal=eda_signal_raw, sampling_rate=fs, show=False)\n        eda_filtered = eda_processed['filtered']\n    else:\n        eda_detrended = detrend(eda_signal_raw, type='linear')\n        eda_filtered = lowpass_filter_eda(eda_detrended, cutoff=1.5, fs=fs)\n    \n    # Adjust signal length if target length is specified\n    if target_len:\n        eda_filtered = eda_filtered[:target_len] if len(eda_filtered) >= target_len else np.pad(eda_filtered, (0, target_len - len(eda_filtered)))\n    return eda_filtered\n\n\n# ===== RESP Preprocessing =====\ndef preprocess_resp_raw(resp_signal_raw, fs=sf_chest, target_len=None, use_biosppy=True):\n    if use_biosppy:\n        resp_processed = biosppy_resp.resp(signal=resp_signal_raw, sampling_rate=fs, show=False)\n        resp_filtered = resp_processed['filtered']\n    else:\n        resp_detrended = detrend(resp_signal_raw, type='linear')\n        resp_filtered = lowpass_filter_resp(resp_detrended, cutoff=0.6, fs=fs)\n\n    # Adjust signal length if target length is specified\n    if target_len:\n        resp_filtered = resp_filtered[:target_len] if len(resp_filtered) >= target_len else np.pad(resp_filtered, (0, target_len - len(resp_filtered)))\n    return resp_filtered\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(df, sid, fs=700, win_sec=30, stride=5,\n               use_biosppy=True, target_len=3500):\n    \"\"\"Preprocess signals for one subject: filtering, normalization, segmentation, and downsampling\"\"\"\n\n    sub_df = df[df['sid'] == sid]\n    ecg_raw = sub_df['ecg'].values.astype(float)\n    resp_raw = sub_df['resp'].values.astype(float)\n    eda_raw = sub_df['eda'].values.astype(float)\n    labels = sub_df['label'].values.astype(int)\n\n    # === Filtering & denoising\n    ecg_filtered = preprocess_ecg_raw(ecg_raw, fs=fs, target_len=len(ecg_raw), use_biosppy=use_biosppy)\n    resp_filtered = preprocess_resp_raw(resp_raw, fs=fs, target_len=len(resp_raw), use_biosppy=use_biosppy)\n    eda_filtered = preprocess_eda_raw(eda_raw, fs=fs, target_len=len(eda_raw), use_biosppy=use_biosppy)\n\n    # === Global normalization\n    ecg_scaled = StandardScaler().fit_transform(ecg_filtered.reshape(-1, 1)).flatten()\n    resp_scaled = StandardScaler().fit_transform(resp_filtered.reshape(-1, 1)).flatten()\n    eda_scaled = MinMaxScaler().fit_transform(eda_filtered.reshape(-1, 1)).flatten()\n\n    # === Window and stride parameters\n    win_len = fs * win_sec\n    stride_len = fs * stride\n\n    X_ecg, X_resp, X_eda = [], [], []\n    y, sub_ids, sample_ids = [], [], []\n    sample_counter = 0\n\n    # Downsampling function\n    def downsample(signal, target_len=3500):\n        return signal[::max(1, len(signal) // target_len)][:target_len]\n\n    # Segment processing function\n    def process_segment(pos, seg_label):\n        nonlocal sample_counter\n        ecg_win = ecg_scaled[pos: pos + win_len]\n        resp_win = resp_scaled[pos: pos + win_len]\n        eda_win = eda_scaled[pos: pos + win_len]\n\n        # === Downsample\n        ecg_down = downsample(ecg_win, target_len)\n        resp_down = downsample(resp_win, target_len)\n        eda_down = downsample(eda_win, target_len)\n\n        X_ecg.append(ecg_down[:, np.newaxis])\n        X_resp.append(resp_down[:, np.newaxis])\n        X_eda.append(eda_down[:, np.newaxis])\n\n        y.append(seg_label)\n        sub_ids.append(f\"S{int(sid)}\")\n        sample_ids.append(f\"S{int(sid)}_sample{sample_counter}\")\n        sample_counter += 1\n\n    # === Segment signals based on continuous labels\n    start_idx = 0\n    for i in range(1, len(labels)):\n        if labels[i] != labels[start_idx] or i == len(labels) - 1:\n            seg_end = i + 1 if i == len(labels) - 1 else i\n            seg_label = labels[start_idx]\n            seg_len = seg_end - start_idx\n\n            if seg_len >= win_len:\n                pos = start_idx\n                while pos + win_len <= seg_end:\n                    process_segment(pos, seg_label)\n                    pos += stride_len\n            elif seg_len >= win_len // 2:\n                # If segment is at least half the window, take one centered sample\n                center = start_idx + seg_len // 2\n                pos = max(0, center - win_len // 2)\n                process_segment(pos, seg_label)\n            else:\n                print(f\"[!] Segment too short and skipped (label={seg_label}, len={seg_len})\")\n\n            start_idx = i\n\n    # === Handle the last segment\n    seg_label = labels[start_idx]\n    if len(labels) - start_idx >= win_len:\n        pos = start_idx\n        while pos + win_len <= len(labels):\n            process_segment(pos, seg_label)\n            pos += stride_len\n\n    return X_ecg, X_eda, X_resp, y, sub_ids, sample_ids\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resample_len = 3500  # Number of points after resampling for all signals\n\n# === Aggregate data from all subjects ===\nX_ecg_all, X_eda_all, X_resp_all = [], [], []\ny_all, sid_all, sample_ids_all = [], [], []\n\nfor sid in fltr_data['sid'].unique():\n    ecg_segs, eda_segs, resp_segs, y, sids, sample_ids = preprocess(fltr_data, sid)\n    \n    X_ecg_all.extend(ecg_segs)\n    X_eda_all.extend(eda_segs)\n    X_resp_all.extend(resp_segs)\n    \n    y_all.extend(y)\n    sid_all.extend(sids)\n    sample_ids_all.extend(sample_ids)\n\n# === Filter out invalid segments with wrong shapes ===\nX_ecg, X_eda, X_resp, y_clean, sid_clean, sample_ids_clean = [], [], [], [], [], []\nexpected_shape = (resample_len, 1)\n\nfor ecg, eda, resp, label, sid, samp_id in zip(\n        X_ecg_all, X_eda_all, X_resp_all, y_all, sid_all, sample_ids_all):\n\n    if ecg.shape == expected_shape and resp.shape == expected_shape and eda.shape == expected_shape:\n        X_ecg.append(ecg)\n        X_eda.append(eda)\n        X_resp.append(resp)\n        y_clean.append(label)\n        sid_clean.append(sid)\n        sample_ids_clean.append(samp_id)\n\n# === Convert to numpy arrays ===\nX_ecg = np.stack(X_ecg)\nX_eda = np.stack(X_eda)\nX_resp = np.stack(X_resp)\ny = np.array(y_clean)\nsid_clean = np.array(sid_clean)\nsample_ids = np.array(sample_ids_clean)\n\n# === Print final results ===\nprint(\"‚úîÔ∏è Valid data after shape check:\")\nprint(\"ECG:\", X_ecg.shape, \"| EDA:\", X_eda.shape, \"| RESP:\", X_resp.shape, \"| Labels:\", y.shape)\nprint(\"Number of unique sample IDs:\", len(np.unique(sample_ids)))\nprint(\"Label distribution:\", Counter(y))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.signal import find_peaks\n\ndef extract_hrv_features(ecg_signal, sampling_rate=700):\n    ecg_signal = ecg_signal.squeeze()\n    try:\n        # Ph√°t hi·ªán R-peaks ƒë∆°n gi·∫£n\n        peaks, _ = find_peaks(ecg_signal, distance=sampling_rate*0.6, height=np.mean(ecg_signal))\n\n        if len(peaks) < 2:\n            raise ValueError(\"Not enough R-peaks\")\n\n        rr_intervals = np.diff(peaks) / sampling_rate  # chuy·ªÉn sang gi√¢y\n\n        # HRV features\n        mean_rr = np.mean(rr_intervals)\n        std_rr = np.std(rr_intervals)\n        rmssd = np.sqrt(np.mean(np.square(np.diff(rr_intervals))))\n        nn50 = np.sum(np.abs(np.diff(rr_intervals)) > 0.05)\n        pnn50 = nn50 / len(rr_intervals)\n\n        return [mean_rr, std_rr, rmssd, nn50, pnn50]\n\n    except Exception as e:\n        print(\"ECG HRV error:\", e)\n        return [np.nan] * 5\n\ndef extract_eda_features(eda_signal):\n    eda_signal = eda_signal.squeeze()\n    try:\n        diff = np.diff(eda_signal)\n        power = np.mean(eda_signal ** 2)\n\n        return [\n            np.mean(eda_signal),\n            np.std(eda_signal),\n            np.max(eda_signal),\n            np.min(eda_signal),\n            np.mean(diff),\n            np.std(diff),\n            power\n        ]\n    except Exception as e:\n        print(\"EDA error:\", e)\n        return [np.nan] * 7\n\ndef extract_resp_features(resp_signal, sampling_rate=700):\n    resp_signal = resp_signal.squeeze()\n    try:\n        # Ph√°t hi·ªán ƒë·ªânh (chu k·ª≥ th·ªü)\n        peaks, _ = find_peaks(resp_signal, distance=sampling_rate*1.5)  # gi·∫£ s·ª≠ t·∫ßn s·ªë th·ªü ~ 0.3‚Äì0.7 Hz\n\n        if len(peaks) < 2:\n            raise ValueError(\"Not enough breaths\")\n\n        intervals = np.diff(peaks) / sampling_rate  # gi√¢y\n        mean_breath_rate = 60 / np.mean(intervals)\n\n        return [\n            np.mean(resp_signal),\n            np.std(resp_signal),\n            np.max(resp_signal),\n            np.min(resp_signal),\n            mean_breath_rate\n        ]\n    except Exception as e:\n        print(\"RESP error:\", e)\n        return [np.nan] * 5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_all_features_custom(X_ecg, X_eda, X_resp, sampling_rate=700):\n    all_features = []\n    for ecg, eda, resp in zip(X_ecg, X_eda, X_resp):\n        feats = (\n            extract_hrv_features(ecg, sampling_rate) +\n            extract_eda_features(eda) +\n            extract_resp_features(resp, sampling_rate)\n        )\n        all_features.append(feats)\n    return np.array(all_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train/Validation/Test Split\n\nIn this step, the dataset is **split by subject IDs** into three non-overlapping subsets: **train**, **validation**, and **test**.  \nThis approach ensures that data from the same subject never appears in multiple splits, avoiding **data leakage**.  \n\n### Main Functions\n1. **`split_by_sid`**  \n   - Filters arrays (`X_ecg`, `X_eda`, `X_resp`, `y`, `sid_arr`, `sample_ids`) according to a given subject ID list.  \n   - Returns only the samples belonging to the specified subjects.\n\n2. **`split_dataset_by_subjects`**  \n   - Randomly splits subject IDs into **train/val/test** groups based on:  \n     - `test_size`: proportion of subjects reserved for val+test.  \n     - `val_ratio`: percentage of val inside the temp set.  \n     - `seed`: random seed for reproducibility.  \n   - Ensures **no subject overlap** between train, val, and test.  \n   - Returns a dictionary containing the three splits and the subject mapping.  \n\n### Verification & Analysis\n- After splitting, the code prints:  \n  1. **Dataset shape** (number of samples per modality, unique subjects, and sample IDs).  \n  2. **Label distribution** (class balance within each split).  \n\n- Finally, a **bar chart** is plotted to show the number of samples for each class (Baseline = 0, Stress = 1, Amusement = 2) across the three subsets.  \n  - Bars are grouped by split (Train, Val, Test).  \n  - Each bar displays the exact count of samples for clarity.  \n  - The plot is saved as `cls_distribution.png`.\n\n### Why Split by Subjects?\n- Physiological signals vary strongly between individuals.  \n- Splitting by samples (random rows) could cause **information leakage** if signals from the same subject appear in both train and test.  \n- By splitting on **subject IDs**, the model is forced to generalize to unseen individuals, making evaluation more realistic.","metadata":{}},{"cell_type":"code","source":"def split_by_sid(X_ecg, X_eda, X_resp, y, sid_arr, sample_ids, sid_list):\n    \"\"\"\n    Filter data based on a list of subject IDs (sid_list).\n    All input data should be numpy arrays.\n    \"\"\"\n    mask = np.isin(sid_arr, sid_list)\n    if not np.any(mask):\n        raise ValueError(\"No subjects found matching sid_list.\")\n\n    return (\n        X_ecg[mask],\n        X_eda[mask],\n        X_resp[mask],\n        y[mask],\n        sid_arr[mask],\n        sample_ids[mask],\n    )\n\ndef split_dataset_by_subjects(X_ecg, X_eda, X_resp, y, sid_arr, sample_ids,\n                               test_size=0.4, val_ratio=0.5, seed=42):\n    \"\"\"\n    Split the dataset into train / validation / test sets by subject ID \n    (ensures no subject leakage across different sets).\n\n    Parameters:\n        - test_size: proportion of subjects assigned to val+test \n                     (e.g., 0.3 -> train gets 70%)\n        - val_ratio: fraction of subjects in val+test that goes to validation \n                     (e.g., 0.5 -> validation = test)\n        - seed: random seed for reproducibility\n\n    Returns:\n        dict containing train / validation / test splits,\n        and the mapping of subject IDs for each split.\n    \"\"\"\n    unique_sids = np.unique(sid_arr)\n\n    # Train / temp split\n    sids_train, sids_temp = train_test_split(\n        unique_sids, test_size=test_size, random_state=seed\n    )\n\n    # Temp => val / test\n    sids_val, sids_test = train_test_split(\n        sids_temp, test_size=val_ratio, random_state=seed\n    )\n\n    # Sanity check\n    assert not (set(sids_train) & set(sids_val)), \"Subjects overlap between train and validation\"\n    assert not (set(sids_train) & set(sids_test)), \"Subjects overlap between train and test\"\n    assert not (set(sids_val) & set(sids_test)), \"Subjects overlap between validation and test\"\n\n    # Extract data for each split\n    X_ecg_train, X_eda_train, X_resp_train, y_train, sid_train, sample_ids_train = split_by_sid(\n        X_ecg, X_eda, X_resp, y, sid_arr, sample_ids, sids_train)\n    X_ecg_val, X_eda_val, X_resp_val, y_val, sid_val, sample_ids_val = split_by_sid(\n        X_ecg, X_eda, X_resp, y, sid_arr, sample_ids, sids_val)\n    X_ecg_test, X_eda_test, X_resp_test, y_test, sid_test, sample_ids_test = split_by_sid(\n        X_ecg, X_eda, X_resp, y, sid_arr, sample_ids, sids_test)\n\n    # Final check: ensure all subjects are included after splitting\n    all_split_sids = set(sid_train.tolist() + sid_val.tolist() + sid_test.tolist())\n    assert all_split_sids == set(unique_sids), \"Some subjects are missing after splitting!\"\n\n    return {\n        \"train\": (X_ecg_train, X_eda_train, X_resp_train, y_train, sid_train, sample_ids_train),\n        \"val\": (X_ecg_val, X_eda_val, X_resp_val, y_val, sid_val, sample_ids_val),\n        \"test\": (X_ecg_test, X_eda_test, X_resp_test, y_test, sid_test, sample_ids_test),\n        \"sid_split\": {\n            \"train\": sids_train,\n            \"val\": sids_val,\n            \"test\": sids_test\n        }\n    }\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"splits = split_dataset_by_subjects(X_ecg, X_eda, X_resp, y, sid_clean, sample_ids)\n\n# === Extract the training set ===\nX_ecg_train, X_eda_train, X_resp_train, y_train, sid_train, sample_ids_train = splits[\"train\"]\n\n# === Extract the validation set ===\nX_ecg_val, X_eda_val, X_resp_val, y_val, sid_val, sample_ids_val = splits[\"val\"]\n\n# === Extract the test set ===\nX_ecg_test, X_eda_test, X_resp_test, y_test, sid_test, sample_ids_test = splits[\"test\"]\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Check dataset dimensions and number of subjects/sample IDs ===\nprint(\"\\nDATASET SHAPE INFORMATION\")\nprint(\"=\" * 60)\n\ndef print_data_shape(name, X_ecg, X_eda, X_resp, y, sid, sample_ids):\n    \"\"\"\n    Print the shape of ECG, EDA, and RESP arrays, \n    along with the number of unique subjects and total samples in each split.\n    \"\"\"\n    print(f\"{name:<6} - ECG: {X_ecg.shape}, EDA: {X_eda.shape}, RESP: {X_resp.shape}, \"\n          f\"Subjects: {len(np.unique(sid))}, Samples: {len(sample_ids)}\")\n\n# Display dataset information for Train, Validation, and Test splits\nprint_data_shape(\"Train\", X_ecg_train, X_eda_train, X_resp_train, y_train, sid_train, sample_ids_train)\nprint_data_shape(\"Val\",   X_ecg_val,   X_eda_val,   X_resp_val,   y_val,   sid_val,   sample_ids_val)\nprint_data_shape(\"Test\",  X_ecg_test,  X_eda_test,  X_resp_test,  y_test,  sid_test,  sample_ids_test)\n\n\n# === Check label distribution (number of samples per class) ===\nprint(\"\\nLABEL DISTRIBUTION\")\nprint(\"=\" * 60)\n\ndef print_label_dist(name, y):\n    \"\"\"\n    Print the distribution of labels for a given dataset split.\n    Each class is shown with the corresponding sample count.\n    \"\"\"\n    counter = Counter(y)\n    label_str = \", \".join([f\"{k}: {v}\" for k, v in sorted(counter.items())])\n    print(f\"{name:<6}: {label_str}\")\n\n# Display label distribution for Train, Validation, and Test splits\nprint_label_dist(\"Train\", y_train)\nprint_label_dist(\"Val\",   y_val)\nprint_label_dist(\"Test\",  y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Count labels in each split (Train, Validation, Test) ===\ncounts_train = Counter(y_train)\ncounts_val = Counter(y_val)\ncounts_test = Counter(y_test)\n\n# === Get the set of class labels (e.g., 0, 1, 2) ===\nclasses = sorted(set(y_train) | set(y_val) | set(y_test))\n\n# === Prepare data structure to store class counts across splits ===\nlabels = ['Train', 'Val', 'Test']\ndata_by_class = {cls: [] for cls in classes}\n\n# Fill the dictionary with sample counts per class for each split\nfor cls in classes:\n    data_by_class[cls] = [\n        counts_train.get(cls, 0),\n        counts_val.get(cls, 0),\n        counts_test.get(cls, 0)\n    ]\n\n\n# === Plot grouped bar chart of class distribution ===\nx = range(len(labels))\nbar_width = 0.2  # adjust width so 3 bars fit within each group\n\nfig, ax = plt.subplots(figsize=(9, 5))\n\n# Define offsets for each class (to shift bars side by side)\noffsets = [-bar_width, 0, bar_width]\ncolors = ['skyblue', 'salmon', 'lightgreen']\n\n# Draw bars for each class\nfor i, cls in enumerate(classes):\n    x_positions = [pos + offsets[i] for pos in x]\n    heights = data_by_class[cls]\n\n    bars = ax.bar(\n        x_positions,\n        heights,\n        width=bar_width,\n        label=f'Class {cls}',\n        color=colors[i % len(colors)]\n    )\n\n    # Add sample counts on top of each bar\n    for bar in bars:\n        height = bar.get_height()\n        ax.text(\n            bar.get_x() + bar.get_width() / 2,\n            height + 5,\n            f'{int(height)}',\n            ha='center',\n            va='bottom',\n            fontsize=9\n        )\n\n# === Customize chart labels and appearance ===\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.set_xlabel('Data splits')\nax.set_ylabel('Sample count')\nax.set_title('Class label distribution among the data splits')\nax.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.2)\nplt.tight_layout()\n\n# Save the figure as a PNG file\nplt.savefig('/kaggle/working/cls_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Augmentation\n\nIn this step, additional training samples are generated by applying transformations to the original signals.  \nThis increases dataset diversity and helps the model generalize better.\n\n### Main Functions\n1. **add_noise(signal, noise_level=0.01)**  \n   - Adds Gaussian noise to the signal.  \n   - `noise_level`: controls the amplitude of the noise.  \n\n2. **time_shift(signal, shift_max=100)**  \n   - Shifts the signal left or right by a random number of samples.  \n   - `shift_max`: maximum shift allowed.  \n\n3. **scaling(signal, scale_range=(0.9, 1.1))**  \n   - Multiplies the signal by a random scaling factor.  \n   - `scale_range`: defines min and max scaling factors.  \n\n4. **augment_dataset(X, y, sid, sample_ids)**  \n   - Applies one or more augmentation functions to the dataset.  \n   - Returns augmented arrays together with original labels and IDs.  \n\n### Verification & Analysis\n- After augmentation, the code prints:  \n  1. New dataset size (original + augmented samples).  \n  2. Proportion of augmented vs. original samples.  \n- Optionally, plots a few augmented signals for visual inspection.  \n\n### Why Data Augmentation?\n- Prevents overfitting by exposing the model to signal variations.  \n- Simulates realistic noise and variability in physiological data.  \n- Helps the model learn more robust features.","metadata":{}},{"cell_type":"code","source":"# === Define augmenters for each physiological signal ===\ndef create_ecg_augmenter(length):\n    return (\n        AddNoise(scale=0.01) +          \n        Drift(max_drift=(0.02, 0.02))  \n        # TimeWarp is omitted because ECG can be distorted too much by time warping\n    ), length\n\ndef create_eda_augmenter(length):\n    return (\n        AddNoise(scale=0.05) * 2 +                      \n        Drift(max_drift=(0.1, 0.1)) +                   \n        TimeWarp(n_speed_change=2, max_speed_ratio=1.5) \n    ), length\n\ndef create_resp_augmenter(length):\n    return (\n        AddNoise(scale=0.02) +                          \n        TimeWarp(n_speed_change=2, max_speed_ratio=1.3) \n        + Drift(max_drift=(0.05, 0.05))                 \n    ), length\n\n\n# === Padding function to ensure all augmented signals have the same length ===\ndef pad_to_length(x_aug, final_len):\n    return np.array([\n        np.pad(x, ((0, final_len - x.shape[0]), (0, 0)), mode='constant')\n        if x.shape[0] < final_len else x\n        for x in x_aug\n    ])\n\n\n# === Augment samples for a specific class with a given number of new samples ===\ndef augment_class(X, y, target_class, n_aug, augmenter, final_len):\n    idx = np.where(y == target_class)[0]\n    if len(idx) == 0:\n        raise ValueError(f\"No samples found for class {target_class}\")\n    \n    # Select all samples belonging to this class\n    X_class = X[idx]\n    \n    # Repeat samples if needed until reaching the target augmentation size\n    n_repeat = int(np.ceil(n_aug / len(X_class)))\n    X_repeat = np.repeat(X_class, n_repeat, axis=0)[:n_aug]\n    \n    # Apply augmentation pipeline\n    X_aug = augmenter.augment(X_repeat)\n    \n    # Pad augmented samples to ensure equal length\n    X_aug = pad_to_length(X_aug, final_len)\n    \n    # Assign the same label for all augmented samples\n    y_aug = np.full((n_aug,), target_class)\n    return X_aug, y_aug\n\n\n# === Augment the training set to balance class distributions ===\ndef augment_train_set(X_ecg, X_eda, X_resp, y, use_random=True, seed=42, plot_distribution=True):\n    # === Automatically compute augmentation plan based on class imbalance ===\n    class_counts = Counter(y)\n    max_count = max(class_counts.values())\n    \n    # Augment minority classes until they match the majority class count\n    augment_plan = {cls: max_count - count for cls, count in class_counts.items() if count < max_count}\n\n    print(f\"[INFO] Original label counts: {dict(class_counts)}\")\n    print(f\"[INFO] Auto augment plan: {augment_plan}\")\n\n    # === Create augmenters for each signal type ===\n    augmenter_ecg, len_ecg = create_ecg_augmenter(X_ecg.shape[1])\n    augmenter_eda, len_eda = create_eda_augmenter(X_eda.shape[1])\n    augmenter_resp, len_resp = create_resp_augmenter(X_resp.shape[1])\n\n    # === Perform augmentation for each underrepresented class ===\n    X_ecg_aug_all, X_eda_aug_all, X_resp_aug_all, y_aug_all = [], [], [], []\n\n    for cls, n_aug in augment_plan.items():\n        ecg_aug, y_cls = augment_class(X_ecg, y, cls, n_aug, augmenter_ecg, len_ecg)\n        eda_aug, _    = augment_class(X_eda, y, cls, n_aug, augmenter_eda, len_eda)\n        resp_aug, _   = augment_class(X_resp, y, cls, n_aug, augmenter_resp, len_resp)\n\n        # Collect augmented data\n        X_ecg_aug_all.append(ecg_aug)\n        X_eda_aug_all.append(eda_aug)\n        X_resp_aug_all.append(resp_aug)\n        y_aug_all.append(y_cls)\n\n    # === Merge original and augmented data ===\n    X_ecg_all = np.concatenate([X_ecg] + X_ecg_aug_all, axis=0)\n    X_eda_all = np.concatenate([X_eda] + X_eda_aug_all, axis=0)\n    X_resp_all = np.concatenate([X_resp] + X_resp_aug_all, axis=0)\n    y_all = np.concatenate([y] + y_aug_all, axis=0)\n\n    # === Shuffle dataset for randomness ===\n    idx = list(range(len(y_all)))\n    if use_random:\n        random.seed(seed)\n        random.shuffle(idx)\n    else:\n        np.random.seed(seed)\n        idx = np.random.permutation(len(y_all))\n\n    # === Analyze class distribution before and after augmentation ===\n    class_labels = {0: 'Baseline', 1: 'Stress', 2: 'Amusement'}\n\n    if plot_distribution:\n        plt.figure(figsize=(10, 4))\n\n        # Before Augmentation\n        plt.subplot(1, 2, 1)\n        plt.title(\"Before Augmentation\")\n        keys = list(class_counts.keys())\n        values = list(class_counts.values())\n        label_names = [class_labels[k] for k in keys]\n        bars1 = plt.bar(label_names, values, color='skyblue')\n        plt.xlabel(\"Class\")\n        plt.ylabel(\"Count\")\n        for bar in bars1:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width() / 2.0, height + 1, str(int(height)),\n                     ha='center', va='bottom')\n\n        # After Augmentation\n        class_counts_aug = Counter(y_all)\n        keys_aug = list(class_counts_aug.keys())\n        values_aug = list(class_counts_aug.values())\n        label_names_aug = [class_labels[k] for k in keys_aug]\n        plt.subplot(1, 2, 2)\n        plt.title(\"After Augmentation\")\n        bars2 = plt.bar(label_names_aug, values_aug, color='lightgreen')\n        plt.xlabel(\"Class\")\n        plt.ylabel(\"Count\")\n        for bar in bars2:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width() / 2.0, height + 1, str(int(height)),\n                     ha='center', va='bottom')\n\n        plt.tight_layout()\n        plt.savefig('/kaggle/working/cls_augment.png', dpi=300, bbox_inches='tight')\n        plt.show()\n\n    return X_ecg_all[idx], X_eda_all[idx], X_resp_all[idx], y_all[idx]\n\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Apply augmentation to balance the training set ===\nX_ecg_train_aug, X_eda_train_aug, X_resp_train_aug, y_train_aug = augment_train_set(\n    X_ecg_train, X_eda_train, X_resp_train, y_train, use_random=True, seed=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Visualization of Augmented Samples ===\ndef plot_samples_by_class(X_ecg, X_eda, X_resp, y, classes_to_plot=None, n_samples=2):\n    unique_classes = sorted(set(y)) if classes_to_plot is None else classes_to_plot\n    for cls in unique_classes:\n        idxs = np.where(y == cls)[0][:n_samples]\n        print(f\"\\n[INFO] Plotting {len(idxs)} samples for class {cls}\")\n        for i, idx in enumerate(idxs):\n            plt.figure(figsize=(15, 4))\n            \n            plt.subplot(3, 1, 1)\n            plt.plot(X_ecg[idx], color='blue')\n            plt.title(f'Class {cls} - Sample {i+1} - ECG')\n            plt.ylabel(\"ECG\")\n            \n            plt.subplot(3, 1, 2)\n            plt.plot(X_eda[idx], color='orange')\n            plt.title(f'EDA')\n            plt.ylabel(\"EDA\")\n            \n            plt.subplot(3, 1, 3)\n            plt.plot(X_resp[idx], color='green')\n            plt.title(f'RESP')\n            plt.ylabel(\"RESP\")\n            plt.xlabel(\"Time\")\n\n            plt.tight_layout()\n            plt.show()\n\nplot_samples_by_class(X_ecg_train_aug, X_eda_train_aug, X_resp_train_aug, y_train_aug, n_samples=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Utilities\n\nIn this section, several helper components are defined to support model training and evaluation:\n\n- **One-hot Encoding**: Converts categorical labels into one-hot vectors for multi-class classification.  \n- **Custom Loss (Focal Loss)**: Designed to handle class imbalance by focusing more on hard-to-classify samples.  \n- **F1 Callback**: Custom callback to monitor the macro-F1 score on the validation set and apply early stopping when no improvement is observed.\n- **Threshold Optimization**: Functions to assign labels based on adaptive thresholds for each class and to search for optimal thresholds that maximize the macro F1 score. \n- **ROC Curve Visualization**: Function to compute and plot ROC curves for each class, including AUC scores.  ","metadata":{}},{"cell_type":"code","source":"# === One-hot encoding for labels ===\ny_train_cat = to_categorical(y_train_aug, num_classes = 3)\ny_val_cat   = to_categorical(y_val, num_classes = 3)\ny_test_cat  = to_categorical(y_test, num_classes = 3)\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Custom Loss: Focal Loss for handling class imbalance ===\n@tf.keras.utils.register_keras_serializable()\nclass FocalLoss(tf.keras.losses.Loss):\n    def __init__(self, gamma=2.0, alpha=1.0, name='focal_loss'):\n        super().__init__(name=name)\n        self.gamma = gamma\n        if isinstance(alpha, (list, tuple)):\n            self.alpha = tf.convert_to_tensor(alpha, dtype=tf.float32)\n        else:\n            self.alpha = tf.constant(alpha, dtype=tf.float32)\n\n    def call(self, y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1. - K.epsilon())\n        ce = -y_true * tf.math.log(y_pred)\n        weight = self.alpha * tf.pow(1 - y_pred, self.gamma)\n        return tf.reduce_sum(weight * ce, axis=1)\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Custom Callback: Monitor macro-F1 and apply early stopping ===\nclass F1Callback(Callback):\n    def __init__(self, val_data):\n        super().__init__()\n        self.validation_data = val_data\n        self.best_f1 = -np.inf\n        self.best_weights = None\n        self.patience = 10\n        self.wait = 0\n\n    def on_epoch_end(self, epoch, logs=None):\n        x_val, y_val_true = self.validation_data\n        y_pred_prob = self.model.predict(x_val)\n        y_pred = np.argmax(y_pred_prob, axis=1)\n        try:\n            y_true = np.argmax(y_val_true, axis=1)\n        except:\n            y_true = y_val_true  # handle sparse labels if needed\n\n        f1_macro = f1_score(y_true, y_pred, average='macro')\n        print(f'\\nEpoch {epoch+1} ‚Äî val_macro_f1: {f1_macro:.4f}')\n\n        if f1_macro > self.best_f1:\n            self.best_f1 = f1_macro\n            self.best_weights = self.model.get_weights()\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                print(\"Early stopping triggered by F1\")\n                self.model.stop_training = True\n                self.model.set_weights(self.best_weights)\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_thresholds(y_probs, thresholds):\n    \"\"\"\n    Assign class labels based on class-specific thresholds.\n    \"\"\"\n    y_pred = np.full(y_probs.shape[0], -1)\n    for i, row in enumerate(y_probs):\n        mask = row >= thresholds\n        if np.any(mask):\n            y_pred[i] = np.argmax(row * mask)  # select the highest probability among classes above threshold\n        else:\n            y_pred[i] = np.argmax(row)  # fallback if no class exceeds threshold\n    return y_pred\n\ndef optimize_thresholds(y_true, y_probs, metric='f1'):\n    \"\"\"\n    Find optimal thresholds for each class by maximizing the macro F1 score.\n    \"\"\"\n    n_classes = y_probs.shape[1]\n    \n    def objective(thresholds):\n        y_pred = apply_thresholds(y_probs, thresholds)\n        score = f1_score(y_true, y_pred, average='macro')\n        return -score  # minimize negative F1 to maximize F1\n\n    init_thresholds = np.full(n_classes, 0.5)\n    bounds = [(0.1, 0.9)] * n_classes\n\n    result = minimize(objective, init_thresholds, method='Powell', bounds=bounds)\n    best_thresholds = result.x\n    return best_thresholds\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Function to plot ROC curves for multi-class classification ===\ndef plot_multiclass_roc(y_true, y_pred_prob, class_names, save_path=None):\n\n    from sklearn.preprocessing import label_binarize\n    from sklearn.metrics import roc_curve, auc\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    n_classes = len(class_names)\n    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n\n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    plt.figure(figsize=(8, 6))\n    for i in range(n_classes):\n        plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n\n    plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve - Multi-class\")\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.tight_layout()\n\n    # Save the ROC curve if a save_path is provided\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        print(f\"üìÅ ROC curve saved to: {save_path}\")\n\n    plt.show()\n\n    macro_roc_auc = np.mean(list(roc_auc.values()))\n    print(f\"\\nMacro ROC AUC: {macro_roc_auc:.4f}\")\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Models  \n\nIn this section, several machine learning and deep learning models are defined and implemented for physiological signal classification.  \nEach model follows a consistent workflow, including **model construction (build)**, **training**, and **evaluation** before moving to the next architecture.  \nThis structured approach ensures a fair comparison across different methods, ranging from traditional classifiers to hybrid deep learning frameworks.  ","metadata":{}},{"cell_type":"markdown","source":"### Hybrid Model  \n\nA hybrid deep learning architecture is implemented to integrate ECG, EDA, and Resp signals.  \nEach physiological modality is processed in an independent branch that combines **CNN** layers for feature extraction, **RNN (GRU)** layers for temporal modeling, and an **attention mechanism** for focusing on relevant signal patterns.  \n\nThe extracted representations are fused through concatenation, followed by fully connected layers to perform final classification.  ","metadata":{}},{"cell_type":"code","source":"def attention_block(x, heads=2, key_dim=8, name=None):\n    attn_layer = MultiHeadAttention(num_heads=heads, key_dim=key_dim, name=name)\n    attn_output, attn_weights = attn_layer(x, x, return_attention_scores=True)\n    attn_output = Add()([x, attn_output])\n    return attn_output, attn_weights \n\ndef build_hybrid_model(input_shape_ecg=(3500, 1), input_shape_eda=(3500, 1), input_shape_resp=(3500, 1), num_classes=3):\n    l2_reg = regularizers.l2(1e-4)\n\n    # === ECG branch ===\n    inp_ecg = Input(shape=input_shape_ecg, name=\"ecg\")\n    x_ecg = Conv1D(16, 7, padding='same', kernel_regularizer=l2_reg)(inp_ecg)\n    x_ecg = BatchNormalization()(x_ecg)\n    x_ecg = Activation('relu')(x_ecg)\n    x_ecg = MaxPooling1D(2)(x_ecg)\n    x_ecg = Bidirectional(GRU(16, return_sequences=True))(x_ecg)\n    x_ecg, attn_ecg = attention_block(x_ecg, name=\"attn_ecg\")\n    x_ecg = Dropout(0.4)(x_ecg)\n    x_ecg = GlobalAveragePooling1D(name=\"gap_ecg\")(x_ecg)\n\n    # === EDA branch ===\n    inp_eda = Input(shape=input_shape_eda, name=\"eda\")\n    x_eda = Conv1D(16, 5, padding='same', kernel_regularizer=l2_reg)(inp_eda)\n    x_eda = BatchNormalization()(x_eda)\n    x_eda = Activation('relu')(x_eda)\n    x_eda = MaxPooling1D(2)(x_eda)\n    x_eda = GRU(16, return_sequences=True)(x_eda)\n    x_eda, attn_eda = attention_block(x_eda, name=\"attn_eda\")\n    x_eda = Dropout(0.4)(x_eda)\n    x_eda = GlobalAveragePooling1D(name=\"gap_eda\")(x_eda)\n\n    # === RESP branch ===\n    inp_resp = Input(shape=input_shape_resp, name=\"resp\")\n    x_resp = Conv1D(16, 7, padding='same', kernel_regularizer=l2_reg)(inp_resp)\n    x_resp = BatchNormalization()(x_resp)\n    x_resp = Activation('relu')(x_resp)\n    x_resp = MaxPooling1D(2)(x_resp)\n    x_resp = Bidirectional(GRU(16, return_sequences=True))(x_resp)\n    x_resp, attn_resp = attention_block(x_resp, name=\"attn_resp\")\n    x_resp = Dropout(0.4)(x_resp)\n    x_resp = GlobalAveragePooling1D(name=\"gap_resp\")(x_resp)\n\n    # === Fusion block ===\n    fused = Concatenate()([x_ecg, x_eda, x_resp])\n    fused = Dense(16, activation='relu', kernel_regularizer=l2_reg)(fused)\n    fused = Dropout(0.3)(fused)\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2_reg)(fused)\n\n    return Model(inputs=[inp_ecg, inp_eda, inp_resp], outputs=output)\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Loss + Optimizer ===\nalpha_list = [1.0, 1.7, 1.2]  # 0: baseline, 1: stress, 2: amusement\nloss_fn = FocalLoss(gamma=1.0, alpha=alpha_list)\noptimizer = AdamW(learning_rate=1e-4, weight_decay=5e-5)\n\n# === Input dicts ===\nx_train = {'ecg': X_ecg_train_aug, 'eda': X_eda_train_aug, 'resp': X_resp_train_aug}\nx_val = {'ecg': X_ecg_val, 'eda': X_eda_val, 'resp': X_resp_val}\n\n# === Callbacks ===\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, mode='min', verbose=1)\nckpt = ModelCheckpoint('model_hybrid_best.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n\nf1_callback = F1Callback(val_data=(x_val, y_val_cat))\n\n# === Build & Compile ===\nmodel = build_hybrid_model()\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n\n# === Training ===\nhistory = model.fit(\n    x=x_train,\n    y=y_train_cat,\n    validation_data=(x_val, y_val_cat),\n    epochs=50,\n    batch_size=32,\n    callbacks=[f1_callback, lr_scheduler, ckpt],\n    shuffle=True,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n\n# ---- Accuracy ----\naxs[0].plot(history.history['accuracy'], label='Train Accuracy')\naxs[0].plot(history.history['val_accuracy'], label='Val Accuracy')\naxs[0].set_title('Training and Validation Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_ylim(bottom=0)\naxs[0].legend()\naxs[0].grid(True)\n\n# ---- Loss ----\naxs[1].plot(history.history['loss'], label='Train Loss')\naxs[1].plot(history.history['val_loss'], label='Val Loss')\naxs[1].set_title('Training and Validation Loss')\naxs[1].set_xlabel('Epoch')\naxs[1].set_ylabel('Loss')\naxs[1].set_ylim(bottom=0)\naxs[1].legend()\naxs[1].grid(True)\n\n# ==== Overall title for the figure ====\nfig.suptitle('Late Fusion Hybrid Model', fontsize=16)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Prediction Phase ===\ny_test_true = np.argmax(y_test_cat, axis=1)\n\nx_test_dict = {\n    'ecg': X_ecg_test,\n    'eda': X_eda_test,\n    'resp': X_resp_test,\n}\n\n# Obtain predicted class probabilities from the trained model\ny_pred_probs = model.predict(x_test_dict, verbose=0)\n\n# --- Threshold Optimization ---\n# Determine the optimal threshold for each class to maximize macro-F1\noptimal_thresholds = optimize_thresholds(y_test_true, y_pred_probs)\nprint(\" Optimal thresholds:\", np.round(optimal_thresholds, 3))\n\n# --- Apply Thresholds ---\n# Generate final predicted labels based on optimized thresholds\ny_pred_cls = apply_thresholds(y_pred_probs, optimal_thresholds)\n\n# === Confusion Matrix ===\n# Visualize classification performance using a confusion matrix\ncm = confusion_matrix(y_test_true, y_pred_cls)\nclass_names = ['Baseline (0)', 'Stress (1)', 'Amusement (2)']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            annot_kws={\"size\": 14})  # Increase annotation font size\nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.title('Confusion Matrix (Test Set, Thresholded)', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig('/kaggle/working/confusion_matrix_test_thresholded.png', dpi=300)\nplt.show()\n\n# === Classification Report ===\n# Print a detailed classification report including precision, recall, and F1-score\nprint(\"\\n Classification Report (with thresholds):\")\nprint(classification_report(y_test_true, y_pred_cls,\n                            target_names=class_names, digits=4))\n\n# === Macro F1-score ===\n# Compute and report the macro-averaged F1 score\nmacro_f1 = f1_score(y_test_true, y_pred_cls, average='macro')\nprint(f\"\\n Macro F1-score: {macro_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_multiclass_roc(\n    y_true=y_test_true,\n    y_pred_prob=y_pred_probs,\n    class_names=['Baseline', 'Stress', 'Amusement'],\n    save_path='/kaggle/working/roc_test_hybrid.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CNN-Only Model\n\nA CNN-only architecture processes ECG, EDA, and Resp signals independently.  \nEach modality passes through a CNN branch (Conv1D ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool ‚Üí GlobalAveragePooling).  \nFeatures from all branches are concatenated and passed through Dense layers with Dropout for final classification.","metadata":{}},{"cell_type":"code","source":"def build_cnn_only_model(input_shape=(3500, 1), num_classes=3):\n    l2_reg = regularizers.l2(1e-4)\n\n    # Each signal passes through its own CNN branch\n    def cnn_branch(inp):\n        x = Conv1D(16, 7, padding='same', kernel_regularizer=l2_reg)(inp)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n        x = MaxPooling1D(2)(x)\n        x = GlobalAveragePooling1D()(x)\n        return x\n\n    inp_ecg = Input(shape=input_shape, name=\"ecg\")\n    inp_eda = Input(shape=input_shape, name=\"eda\")\n    inp_resp = Input(shape=input_shape, name=\"resp\")\n\n    x_ecg = cnn_branch(inp_ecg)\n    x_eda = cnn_branch(inp_eda)\n    x_resp = cnn_branch(inp_resp)\n\n    fused = Concatenate()([x_ecg, x_eda, x_resp])\n    fused = Dense(16, activation='relu', kernel_regularizer=l2_reg)(fused)\n    fused = Dropout(0.3)(fused)\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2_reg)(fused)\n\n    return Model(inputs=[inp_ecg, inp_eda, inp_resp], outputs=output)\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Loss + Optimizer ===\nalpha_list = [1.0, 1.7, 1.2]\nloss_fn = FocalLoss(gamma=1.0, alpha = alpha_list)\noptimizer = AdamW(learning_rate=1e-4, weight_decay=5e-5)\n\n# === Input dicts ===\nx_train = {'ecg': X_ecg_train_aug, 'eda': X_eda_train_aug, 'resp': X_resp_train_aug}\nx_val = {'ecg': X_ecg_val, 'eda': X_eda_val, 'resp': X_resp_val}\n\n# === Callbacks ===\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, mode='min', verbose=1)\nckpt_cnn = ModelCheckpoint('model_hcnn_only.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n\nf1_callback = F1Callback(val_data=(x_val, y_val_cat))\n\n# === Build & Compile ===\ncnn_model = build_cnn_only_model()\ncnn_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n\n# === Fit ===\ncnn_history = cnn_model.fit(\n    x=x_train,\n    y=y_train_cat,\n    validation_data=(x_val, y_val_cat),\n    epochs=50,\n    batch_size=32,\n    callbacks=[f1_callback, lr_scheduler, ckpt_cnn],\n    shuffle=True,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n\n# ---- Accuracy ----\naxs[0].plot(cnn_history.history['accuracy'], label='Train Accuracy')\naxs[0].plot(cnn_history.history['val_accuracy'], label='Val Accuracy')\naxs[0].set_title('Training and Validation Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_ylim(bottom=0)\naxs[0].legend()\naxs[0].grid(True)\n\n# ---- Loss ----\naxs[1].plot(cnn_history.history['loss'], label='Train Loss')\naxs[1].plot(cnn_history.history['val_loss'], label='Val Loss')\naxs[1].set_title('Training and Validation Loss')\naxs[1].set_xlabel('Epoch')\naxs[1].set_ylabel('Loss')\naxs[1].set_ylim(bottom=0)\naxs[1].legend()\naxs[1].grid(True)\n\n# ==== Overall title for the figure ====\nfig.suptitle('CNN-only Model', fontsize=16)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Prediction Phase ===\ny_pred_probs_cnn = cnn_model.predict(x_test_dict, verbose=0)\n\n# --- Threshold Optimization ---\n# Determine the optimal threshold for each class to maximize macro-F1\noptimal_thresholds_cnn = optimize_thresholds(y_test_true, y_pred_probs_cnn)\nprint(\" Optimal thresholds:\", np.round(optimal_thresholds_cnn, 3))\n\n# --- Apply Thresholds ---\n# Generate final predicted labels based on optimized thresholds\ny_pred_cls_cnn = apply_thresholds(y_pred_probs_cnn, optimal_thresholds_cnn)\n\n# === Confusion Matrix ===\n# Visualize classification performance using a confusion matrix\ncnn_cm = confusion_matrix(y_test_true, y_pred_cls_cnn)\nclass_names = ['Baseline (0)', 'Stress (1)', 'Amusement (2)']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cnn_cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            annot_kws={\"size\": 14}) \nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.title('Confusion Matrix (Test Set, Thresholded)', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig('/kaggle/working/cnn_confusion_matrix_test.png', dpi=300)\nplt.show()\n\n# === Classification Report ===\n# Print a detailed classification report including precision, recall, and F1-score\nprint(\"\\n Classification Report (with thresholds):\")\nprint(classification_report(y_test_true, y_pred_cls_cnn,\n                            target_names=class_names, digits=4))\n\n# === Macro F1-score ===\n# Compute and report the macro-averaged F1 score\ncnn_macro_f1 = f1_score(y_test_true, y_pred_cls_cnn, average='macro')\nprint(f\"\\n Macro F1-score: {cnn_macro_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_multiclass_roc(\n    y_true=y_test_true,\n    y_pred_prob=y_pred_probs_cnn,\n    class_names=['Baseline', 'Stress', 'Amusement'],\n    save_path='/kaggle/working/roc_test_cnn.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### RNN-Only Model\n\nA RNN-only architecture processes ECG, EDA, and Resp signals independently.  \nEach modality passes through a GRU branch (Bidirectional or unidirectional GRU ‚Üí GlobalAveragePooling) to capture temporal patterns.  \n\nFeatures from all branches are concatenated and passed through Dense layers with Dropout for final classification.","metadata":{}},{"cell_type":"code","source":"def build_bigru_only_model(input_shape=(3500, 1), num_classes=3):\n    l2_reg = regularizers.l2(1e-4)\n\n    def rnn_branch(inp, use_bi=True):\n        if use_bi:\n            x = Bidirectional(GRU(16, return_sequences=True))(inp)\n        else:\n            x = GRU(16, return_sequences=True)(inp)\n        x = GlobalAveragePooling1D()(x)\n        return x\n\n    inp_ecg = Input(shape=input_shape, name=\"ecg\")\n    inp_eda = Input(shape=input_shape, name=\"eda\")\n    inp_resp = Input(shape=input_shape, name=\"resp\")\n\n    x_ecg = rnn_branch(inp_ecg, use_bi=True)\n    x_eda = rnn_branch(inp_eda, use_bi=False) \n    x_resp = rnn_branch(inp_resp, use_bi=True)\n\n    fused = Concatenate()([x_ecg, x_eda, x_resp])\n    fused = Dense(16, activation='relu', kernel_regularizer=l2_reg)(fused)\n    fused = Dropout(0.3)(fused)\n    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2_reg)(fused)\n\n    return Model(inputs=[inp_ecg, inp_eda, inp_resp], outputs=output)\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Loss + Optimizer ===\nalpha_list = [1.0, 1.7, 1.2]\nloss_fn = FocalLoss(gamma=1.0, alpha = alpha_list)\noptimizer = AdamW(learning_rate=1e-4, weight_decay=5e-5)\n\n# === Input dicts ===\nx_train = {'ecg': X_ecg_train_aug, 'eda': X_eda_train_aug, 'resp': X_resp_train_aug}\nx_val = {'ecg': X_ecg_val, 'eda': X_eda_val, 'resp': X_resp_val}\n\n# === Callbacks ===\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, mode='min', verbose=1)\nckpt_rnn = ModelCheckpoint('model_rnn_only.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n\nf1_callback = F1Callback(val_data=(x_val, y_val_cat))\n\n# === Build & Compile ===\nrnn_model = build_bigru_only_model()\nrnn_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n\n# === Fit ===\nrnn_history = rnn_model.fit(\n    x=x_train,\n    y=y_train_cat,\n    validation_data=(x_val, y_val_cat),\n    epochs=50,\n    batch_size=32,\n    callbacks=[f1_callback, lr_scheduler, ckpt_rnn],\n    shuffle=True,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n\n# ---- Accuracy ----\naxs[0].plot(rnn_history.history['accuracy'], label='Train Accuracy')\naxs[0].plot(rnn_history.history['val_accuracy'], label='Val Accuracy')\naxs[0].set_title('Training and Validation Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_ylim(bottom=0)\naxs[0].legend()\naxs[0].grid(True)\n\n# ---- Loss ----\naxs[1].plot(rnn_history.history['loss'], label='Train Loss')\naxs[1].plot(rnn_history.history['val_loss'], label='Val Loss')\naxs[1].set_title('Training and Validation Loss')\naxs[1].set_xlabel('Epoch')\naxs[1].set_ylabel('Loss')\naxs[1].set_ylim(bottom=0)\naxs[1].legend()\naxs[1].grid(True)\n\n# ==== Overall title for the figure ====\nfig.suptitle('RNN-only Model', fontsize=16)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Prediction Phase ===\ny_pred_probs_rnn = rnn_model.predict(x_test_dict, verbose=0)\n\n# --- Threshold Optimization ---\n# Determine the optimal threshold for each class to maximize macro-F1\noptimal_thresholds_rnn = optimize_thresholds(y_test_true, y_pred_probs_rnn)\nprint(\" Optimal thresholds:\", np.round(optimal_thresholds_rnn, 3))\n\n# --- Apply Thresholds ---\n# Generate final predicted labels based on optimized thresholds\ny_pred_cls_rnn = apply_thresholds(y_pred_probs_rnn, optimal_thresholds_rnn)\n\n# === Confusion Matrix ===\n# Visualize classification performance using a confusion matrix\nrnn_cm = confusion_matrix(y_test_true, y_pred_cls_rnn)\nclass_names = ['Baseline (0)', 'Stress (1)', 'Amusement (2)']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(rnn_cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            annot_kws={\"size\": 14})  \nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.title('Confusion Matrix (Test Set, Thresholded)', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig('/kaggle/working/rnn_confusion_matrix_test.png', dpi=300)\nplt.show()\n\n# === Classification Report ===\n# Print a detailed classification report including precision, recall, and F1-score\nprint(\"\\n Classification Report (with thresholds):\")\nprint(classification_report(y_test_true, y_pred_cls_rnn,\n                            target_names=class_names, digits=4))\n\n# === Macro F1-score ===\n# Compute and report the macro-averaged F1 score\nrnn_macro_f1 = f1_score(y_test_true, y_pred_cls_rnn, average='macro')\nprint(f\"\\n Macro F1-score: {rnn_macro_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_multiclass_roc(\n    y_true=y_test_true,\n    y_pred_prob=y_pred_probs_rnn,\n    class_names=['Baseline', 'Stress', 'Amusement'],\n    save_path='/kaggle/working/roc_test_rnn.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SVM Model\n\nThe SVM model uses handcrafted features extracted from ECG, EDA, and Resp signals.  \n\n**Pipeline:**\n1. Feature extraction (`extract_all_features_custom`) for each modality  \n2. Standardization using `StandardScaler`  \n3. Train SVM classifier with RBF kernel (`SVC`)  \n4. Predict class labels and probabilities on the test set","metadata":{}},{"cell_type":"code","source":"# Feature extraction\nX_train_feat = extract_all_features_custom(X_ecg_train, X_eda_train, X_resp_train)\nX_test_feat  = extract_all_features_custom(X_ecg_test,  X_eda_test,  X_resp_test)\n\n# Standardization\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_feat)\nX_test_scaled = scaler.transform(X_test_feat)\n\n# Train SVM\nsvm_clf = SVC(probability=True, kernel='rbf', C=1.0, random_state=42)\nsvm_clf.fit(X_train_scaled, y_train)\n\n# Prediction\ny_pred_svm = svm_clf.predict(X_test_scaled)\ny_prob_svm = svm_clf.predict_proba(X_test_scaled)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = ['Baseline', 'Stress', 'Amusement']\n\n# === Confusion Matrix ===\n# Visualize classification performance using a confusion matrix\ncm_svm = confusion_matrix(y_test, y_pred_svm)\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            annot_kws={\"size\": 14})\nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.title('Confusion Matrix (SVM)', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig('/kaggle/working/confusion_matrix_svm.png', dpi=300)\nplt.show()\n\n# === Classification Report ===\n# Print a detailed classification report including precision, recall, and F1-score\nprint(\"\\n Classification Report (SVM):\")\nprint(classification_report(y_test, y_pred_svm,\n                            target_names=class_names,\n                            digits=4))\n\n# === Macro F1-score ===\n# Compute and report the macro-averaged F1 score\nmacro_f1_svm = f1_score(y_test, y_pred_svm, average='macro')\nprint(f\"\\n Macro F1-score: {macro_f1_svm:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_multiclass_roc(\n    y_true=y_test,\n    y_pred_prob=y_prob_svm,\n    class_names=class_names,\n    save_path='/kaggle/working/roc_svm_baseline.png'  \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forest Model\n\nA Random Forest classifier is trained on handcrafted features from ECG, EDA, and Resp signals.  \n\n**Pipeline:**\n1. Feature extraction for each modality  \n2. Initialize `RandomForestClassifier` (e.g., 200 trees, max depth 10, balanced class weights)  \n3. Train the model on the training set  \n4. Predict on the test set","metadata":{}},{"cell_type":"code","source":"# Initialize model\nrf = RandomForestClassifier(\n    n_estimators=200,\n    max_depth=10,\n    random_state=42,\n    class_weight='balanced'  \n)\n\n# Train the model\nrf.fit(X_train_feat, y_train)\n\n# Predict labels\ny_pred_rf = rf.predict(X_test_feat)\n\n# Predict probabilities (for ROC)\ny_prob_rf = rf.predict_proba(X_test_feat)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Confusion Matrix ===\n# Visualize classification performance using a confusion matrix\ncm_rf = confusion_matrix(y_test, y_pred_rf)\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names,\n            annot_kws={\"size\": 14})\nplt.xlabel('Predicted Label', fontsize=12)\nplt.ylabel('True Label', fontsize=12)\nplt.title('Confusion Matrix (Random Forest)', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig('/kaggle/working/confusion_matrix_rf.png', dpi=300)\nplt.show()\n\n# === Classification Report ===\n# Print a detailed classification report including precision, recall, and F1-score\nprint(\"\\n Classification Report (Random Forest):\")\nprint(classification_report(y_test, y_pred_rf,\n                            target_names=class_names,\n                            digits=4))\n\n# === Macro F1-score ===\n# Compute and report the macro-averaged F1 score\nmacro_f1_rf = f1_score(y_test, y_pred_rf, average='macro')\nprint(f\"\\n Macro F1-score (Random Forest): {macro_f1_rf:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_multiclass_roc(\n    y_true=y_test,\n    y_pred_prob=y_prob_rf,\n    class_names=class_names,\n    save_path='/kaggle/working/roc_curve_rf.png'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Error Analysis of the Hybrid Model\n\nThis section investigates the misclassifications of the hybrid model to better understand its limitations and strengths.","metadata":{}},{"cell_type":"code","source":"# Mapping nh√£n s·ªë sang t√™n l·ªõp\nclass_map = {0: 'Baseline', 1: 'Stress', 2: 'Amusement'}\n\n# Danh s√°ch l∆∞u k·∫øt qu·∫£ l·ªói\nerror_rows = []\n\nfor i in range(len(y_test_true)):\n    if y_pred_cls[i] != y_test_true[i]:\n        # Tr√≠ch sample g√¢y l·ªói\n        input_sample = {\n            'ecg': x_test_dict['ecg'][i:i+1],\n            'eda': x_test_dict['eda'][i:i+1],\n            'resp': x_test_dict['resp'][i:i+1]\n        }\n\n        # L·∫•y attention t·ª´ model ph·ª•\n        attn_ecg, attn_eda, attn_resp, _ = attn_model.predict(input_sample, verbose=0)\n\n        # T·ªïng attention t·ª´ng modality\n        attn_total = {\n            'ECG': np.sum(attn_ecg[0]),    # shape: (time, dim)\n            'EDA': np.sum(attn_eda[0]),\n            'RESP': np.sum(attn_resp[0])\n        }\n\n        # Modal ch√≠nh ƒë∆∞·ª£c ch√∫ √Ω nhi·ªÅu nh·∫•t\n        dominant_modality = max(attn_total, key=attn_total.get)\n\n        # Ghi l·∫°i th√¥ng tin l·ªói\n        error_rows.append({\n            'Sample Index': i,\n            'True Label': class_map[y_test_true[i]],\n            'Predicted': class_map[y_pred_cls[i]],\n            'Dominant Modality': dominant_modality,\n            'ECG Attention Sum': round(attn_total['ECG'], 3),\n            'EDA Attention Sum': round(attn_total['EDA'], 3),\n            'RESP Attention Sum': round(attn_total['RESP'], 3),\n        })\n\n# Chuy·ªÉn th√†nh DataFrame\ndf_error_by_class = pd.DataFrame(error_rows)\n\n# T·∫°o b·∫£ng t√≥m t·∫Øt theo (True Label ‚Üí Predicted ‚Üí Dominant Modality)\nsummary = df_error_by_class.groupby(['True Label', 'Predicted', 'Dominant Modality']).size().unstack(fill_value=0)\n\n# üîç Hi·ªÉn th·ªã b·∫£ng t√≥m t·∫Øt\nprint(\"\\n B·∫£ng ph√¢n t√≠ch l·ªói theo nh√£n th·∫≠t, d·ª± ƒëo√°n sai v√† modality tr·ªôi:\")\nprint(summary)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# T·∫°o DataFrame t·ªïng h·ª£p l·ªói\ndf_errors = pd.DataFrame({\n    'Sample': np.arange(len(y_test_true)),\n    'Subject': sid_test,\n    'True Label': y_test_true,\n    'Predicted': y_pred_cls\n})\n\n# Th√™m c·ªôt ƒë√°nh d·∫•u ƒë√∫ng/sai\ndf_errors['Correct'] = df_errors['True Label'] == df_errors['Predicted']\n\n# √Ånh x·∫° nh√£n s·ªë sang t√™n l·ªõp\ndf_errors['True Label Name'] = df_errors['True Label'].map(class_map)\ndf_errors['Predicted Name'] = df_errors['Predicted'].map(class_map)\n\n# (T√πy ch·ªçn) Hi·ªÉn th·ªã m·ªôt s·ªë d√≤ng ƒë·∫ßu ti√™n ƒë·ªÉ ki·ªÉm tra\nprint(\"\\n T·ªïng h·ª£p l·ªói d·ª± ƒëo√°n:\")\nprint(df_errors.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# T·∫°o b·∫£ng ƒë·∫øm l·ªói theo Subject v√† l·ªõp th·∫≠t\nerrors_by_subject_class = df_errors[df_errors['Correct'] == False].groupby(['Subject', 'True Label Name']).agg(\n    misclassified=('Sample', 'count')\n).reset_index()\n\nprint(\"\\n Misclassified Samples per Subject per Class:\")\nprint(errors_by_subject_class.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# T√≠nh accuracy theo t·ª´ng Subject v√† Class\nacc_by_subject_class = df_errors.groupby(['Subject', 'True Label Name']).agg(\n    total=('Sample', 'count'),\n    correct=('Correct', 'sum')\n).reset_index()\n\n# Th√™m c·ªôt accuracy n·∫øu c·∫ßn (t√πy m·ª•c ƒë√≠ch)\nacc_by_subject_class['accuracy'] = (acc_by_subject_class['correct'] / acc_by_subject_class['total']).round(3)\n\nprint(\"\\n Accuracy per Subject per Class:\")\nprint(acc_by_subject_class.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# G·ªôp v·ªõi b·∫£ng t·ªïng s·ªë m·∫´u ƒë·ªÉ t√≠nh error rate\nerror_rate_by_subject_class = pd.merge(\n    acc_by_subject_class,\n    errors_by_subject_class,\n    on=['Subject', 'True Label Name'],\n    how='left'\n)\n\n# ƒêi·ªÅn 0 n·∫øu kh√¥ng c√≥ l·ªói n√†o\nerror_rate_by_subject_class['misclassified'] = error_rate_by_subject_class['misclassified'].fillna(0).astype(int)\n\n# T√≠nh error rate\nerror_rate_by_subject_class['error_rate'] = (error_rate_by_subject_class['misclassified'] / error_rate_by_subject_class['total']).round(3)\n\nprint(\"\\n Error Rate per Subject per Class:\")\nprint(error_rate_by_subject_class.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Mean Activation Analysis\n\nThis section analyzes the contributions of each modality branch (ECG, EDA, Resp) in the hybrid model.\n\n**Steps:**\n1. Create a sub-model to extract outputs from the three branches and the final softmax output.\n2. Predict on the test set using the sub-model.\n3. Compute predicted labels by applying optimal thresholds.\n4. Calculate mean activation for each branch grouped by predicted emotion labels.\n5. Visualize the mean activations using a bar chart.\n","metadata":{}},{"cell_type":"code","source":"# === Create sub-model to extract outputs from 3 branches ===\nbranch_model = Model(\n    inputs=model.input,\n    outputs=[\n        model.get_layer(\"gap_ecg\").output,\n        model.get_layer(\"gap_eda\").output,\n        model.get_layer(\"gap_resp\").output,\n        model.output  # softmax ƒë·∫ßu ra\n    ]\n)\n\n# === Predict on test set ===\necg_vec, eda_vec, resp_vec, y_pred_prob = branch_model.predict(x_test_dict, verbose=0)\n\n# === Compute predicted labels (after thresholding) ===\noptimal_thresholds = optimize_thresholds(np.argmax(y_test_cat, axis=1), y_pred_prob)\ny_pred_cls = apply_thresholds(y_pred_prob, optimal_thresholds)\n\n# === Compute mean activation per branch grouped by label ===\ndf = pd.DataFrame({\n    'Label': y_pred_cls,\n    'ECG': ecg_vec.mean(axis=1),\n    'EDA': eda_vec.mean(axis=1),\n    'RESP': resp_vec.mean(axis=1)\n})\nmean_activation = df.groupby('Label').mean().round(6)\nlabel_map = {0: 'Baseline', 1: 'Stress', 2: 'Amusement'}\nmean_activation.index = mean_activation.index.map(label_map)\n\nprint(\" Mean Activation Per Branch (Grouped by Predicted Emotion):\\n\")\nprint(mean_activation)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Bar chart ===\nmean_activation.plot(kind='bar', figsize=(8, 5), colormap='viridis')\nplt.title(\"Mean Signal Activation per Emotion\")\nplt.ylabel(\"Mean Activation\")\nplt.xticks(rotation=0)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig('/kaggle/working/mean_activation.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Attention Weight Analysis\n\nThis section analyzes the attention mechanisms of the hybrid model to interpret how the model focuses on important temporal patterns in physiological signals.\n\n**Components:**\n1. **Temporal Attention**  \n   - Extract attention weights from the RNN/GRU layers.  \n   - Visualize the distribution of attention over time to identify which signal segments contribute most to the prediction.\n\n2. **Attention Entropy**  \n   - Compute the entropy of attention weights as a measure of how concentrated or distributed the model's focus is.  \n   - Lower entropy indicates focused attention on specific segments, while higher entropy indicates more distributed attention.\n","metadata":{}},{"cell_type":"markdown","source":"### Temporal Attention","metadata":{}},{"cell_type":"code","source":"# === T·∫°o model ph·ª• ƒë·ªÉ l·∫•y attention ===\nattn_model = Model(\n    inputs=model.input,\n    outputs=[\n        model.get_layer(\"attn_ecg\").output[1],   # attention weights ECG\n        model.get_layer(\"attn_eda\").output[1],   # attention weights EDA\n        model.get_layer(\"attn_resp\").output[1],  # attention weights RESP\n        model.output                             # output softmax\n    ]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === T·∫°o th∆∞ m·ª•c l∆∞u overlay ===\nos.makedirs(\"heatmaps_overlay/correct\", exist_ok=True)\nos.makedirs(\"heatmaps_overlay/incorrect\", exist_ok=True)\n\n# === Ch·ªçn ng·∫´u nhi√™n 20 m·∫´u ===\nrandom_indices = np.random.choice(len(y_test_true), size=50, replace=False)\n\nfor idx in random_indices:\n    # --- L·∫•y d·ªØ li·ªáu ---\n    sample_input = [\n        x_test_dict['ecg'][idx:idx+1],\n        x_test_dict['eda'][idx:idx+1],\n        x_test_dict['resp'][idx:idx+1]\n    ]\n\n    attn_ecg, attn_eda, attn_resp, softmax_out = attn_model.predict(sample_input)\n\n    mean_attn_ecg = attn_ecg.mean(axis=1)[0].mean(axis=0)\n    mean_attn_eda = attn_eda.mean(axis=1)[0].mean(axis=0)\n    mean_attn_resp = attn_resp.mean(axis=1)[0].mean(axis=0)\n\n    true_label = y_test_true[idx]\n    pred_label = np.argmax(softmax_out)\n\n    # --- Chu·∫©n b·ªã t√≠n hi·ªáu v√† attention ---\n    sig_ecg = x_test_dict['ecg'][idx].squeeze()\n    sig_eda = x_test_dict['eda'][idx].squeeze()\n    sig_resp = x_test_dict['resp'][idx].squeeze()\n    \n    signals = {\n        'ECG': sig_ecg,\n        'EDA': sig_eda,\n        'RESP': sig_resp\n    }\n    signal_cmaps = {\n        'ECG': 'Reds',   # ƒë·ªè nh·∫°t ƒë·∫øn ƒë·∫≠m\n        'EDA': 'Greens',    # xanh l√° nh·∫°t ƒë·∫øn ƒë·∫≠m\n        'RESP': 'Blues'   # xanh d∆∞∆°ng nh·∫°t ƒë·∫øn ƒë·∫≠m\n    }\n    attentions = {\n        'ECG': mean_attn_ecg,\n        'EDA': mean_attn_eda,\n        'RESP': mean_attn_resp\n    }\n\n    # === V·∫Ω overlay attention ===\n    fig, axs = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n\n    for i, key in enumerate(['ECG', 'EDA', 'RESP']):\n        sig = signals[key]\n        attn = attentions[key]\n\n        # Resample attention n·∫øu kh√¥ng kh·ªõp ƒë·ªô d√†i\n        if len(attn) != len(sig):\n            attn = np.interp(\n                np.linspace(0, 1, len(sig)),\n                np.linspace(0, 1, len(attn)),\n                attn\n            )\n\n        # Chu·∫©n h√≥a attention v·ªÅ [0, 1]\n        attn_norm = (attn - attn.min()) / (attn.max() - attn.min() + 1e-8)\n\n        axs[i].plot(sig, color='black', label=key)\n\n        # D√πng imshow ƒë·ªÉ overlay attention nh∆∞ heatmap\n        axs[i].imshow(\n            attn_norm[np.newaxis, :],\n            aspect='auto',\n            cmap=signal_cmaps[key],\n            alpha=0.6,\n            extent=[0, len(sig), sig.min(), sig.max()],\n            interpolation='bilinear',\n            origin='lower'\n        )\n\n        axs[i].set_ylabel(key)\n        axs[i].legend(loc='upper right')\n\n    axs[2].set_xlabel(\"Timestep\")\n    plt.suptitle(f\"Overlay Attention + Signal (True: {true_label}, Pred: {pred_label})\", fontsize=14)\n    plt.tight_layout()\n\n    fname_overlay = f\"overlay_{idx}_T{true_label}_P{pred_label}.png\"\n    overlay_path = f\"heatmaps_overlay/{'correct' if true_label == pred_label else 'incorrect'}/{fname_overlay}\"\n    plt.savefig(overlay_path, dpi=300)\n    plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Attention Entropy","metadata":{}},{"cell_type":"code","source":"# ======== H√†m t√≠nh entropy v√† tr√≠ch vector attention ========\n\ndef attention_entropy(attn_weights, epsilon=1e-8):\n    attn_weights = np.clip(attn_weights, epsilon, 1.0)\n    return -np.sum(attn_weights * np.log(attn_weights))\n\ndef extract_attention_vector(attn_matrix):\n    \"\"\"\n    Tr√≠ch vector attention 1D t·ª´ tensor [1, heads, T, T]\n    - Trung b√¨nh qua all heads\n    - Trung b√¨nh theo tr·ª•c Q (query)\n    - Chu·∫©n h√≥a ƒë·ªÉ t·ªïng = 1\n    Tr·∫£ v·ªÅ vector (T,)\n    \"\"\"\n    # Shape: (1, heads, T, T)\n    attn_avg = np.mean(attn_matrix, axis=1)         # (1, T, T)\n    attn_mean_query = np.mean(attn_avg[0], axis=0)  # (T,)\n    attn_norm = attn_mean_query / np.sum(attn_mean_query + 1e-8)\n    return attn_norm\n\n# ======== T√≠nh entropy cho t·ª´ng m·∫´u test ========\n\nclass_map = {0: 'Baseline', 1: 'Stress', 2: 'Amusement'}\nentropy_by_class = {\n    'ECG': defaultdict(list),\n    'EDA': defaultdict(list),\n    'RESP': defaultdict(list)\n}\n\nfor i in range(len(y_test_true)):\n    label = y_test_true[i]\n\n    sample_input = {\n        'ecg': x_test_dict['ecg'][i:i+1],\n        'eda': x_test_dict['eda'][i:i+1],\n        'resp': x_test_dict['resp'][i:i+1]\n    }\n\n    # Tr√≠ch attention t·ª´ model ph·ª•\n    attn_ecg, attn_eda, attn_resp, _ = attn_model.predict(sample_input, verbose=0)\n\n    # T√≠nh vector attention v√† entropy\n    vec_ecg = extract_attention_vector(attn_ecg)\n    vec_eda = extract_attention_vector(attn_eda)\n    vec_resp = extract_attention_vector(attn_resp)\n\n    entropy_by_class['ECG'][label].append(attention_entropy(vec_ecg))\n    entropy_by_class['EDA'][label].append(attention_entropy(vec_eda))\n    entropy_by_class['RESP'][label].append(attention_entropy(vec_resp))\n\n# ======== Hi·ªÉn th·ªã entropy trung b√¨nh theo class & modality ========\n\nprint(\"\\n Entropy trung b√¨nh theo l·ªõp v√† modality:\")\nfor modality in ['ECG', 'EDA', 'RESP']:\n    print(f\"\\n Modality: {modality}\")\n    for label, ent_list in entropy_by_class[modality].items():\n        mean_entropy = np.mean(ent_list)\n        std_entropy = np.std(ent_list)\n        print(f\"  {class_map[label]}: Mean = {mean_entropy:.4f}, Std = {std_entropy:.4f}\")\n\n# ======== T·∫°o DataFrame ƒë·ªÉ v·∫Ω boxplot ========\n\nentropy_records = []\n\nfor modality in ['ECG', 'EDA', 'RESP']:\n    for label, ent_list in entropy_by_class[modality].items():\n        for ent in ent_list:\n            entropy_records.append({\n                'Modality': modality,\n                'Class': class_map[label],\n                'Entropy': ent\n            })\n\ndf_entropy = pd.DataFrame(entropy_records)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## K-Fold Cross-Validation\n\nThis section describes the use of K-Fold cross-validation to evaluate model performance more robustly.\n\n**Steps:**\n1. Split the dataset into K equal folds.\n2. For each fold:\n   - Use one fold as the validation set and the remaining K-1 folds as the training set.\n   - Train the model on the training set and evaluate on the validation set.\n3. Repeat for all K folds and compute the average performance metrics.\n4. This approach reduces variance and provides a more reliable estimate of the model's generalization ability.","metadata":{}},{"cell_type":"markdown","source":"### Prepare data for K-Fold deep learning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n# === ƒê·∫£m b·∫£o c√°c bi·∫øn l√† numpy arrays ===\nassert X_ecg.shape[0] == y.shape[0] == sid_clean.shape[0]\n\n# === Danh s√°ch unique subject ID ===\nunique_sid = np.unique(sid_clean)\nassert len(unique_sid) % 5 == 0, \"S·ªë subject ph·∫£i chia h·∫øt cho 5 ƒë·ªÉ chia fold ƒë·ªÅu\"\n\n# === KFold chia theo subject ID ===\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nresults = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hybrid model 5-fold","metadata":{}},{"cell_type":"code","source":"# === ƒê·ªãnh nghƒ©a h√†m build model ===\ndef build_model_kfold():\n    model = build_hybrid_model()\n    alpha_list = [1.0, 1.7, 1.2]\n    loss_fn = FocalLoss(gamma=1.0, alpha=alpha_list)\n    optimizer = AdamW(learning_rate=1e-4, weight_decay=5e-5)\n    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n    return model\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === V√≤ng l·∫∑p theo t·ª´ng fold ===\nfor fold_idx, (train_subj_idx, test_subj_idx) in enumerate(kf.split(unique_sid)):\n    train_subjects = unique_sid[train_subj_idx]\n    test_subjects = unique_sid[test_subj_idx]\n\n    train_mask = np.isin(sid_clean, train_subjects)\n    test_mask = np.isin(sid_clean, test_subjects)\n\n    X_ecg_train, X_eda_train, X_resp_train = X_ecg[train_mask], X_eda[train_mask], X_resp[train_mask]\n    X_ecg_test, X_eda_test, X_resp_test = X_ecg[test_mask], X_eda[test_mask], X_resp[test_mask]\n    y_train, y_test = y[train_mask], y[test_mask]\n\n    # === Augmentation ===\n    X_ecg_train_aug, X_eda_train_aug, X_resp_train_aug, y_train_aug = augment_train_set(\n        X_ecg_train, X_eda_train, X_resp_train, y_train,\n        use_random=True, seed=42, plot_distribution=False\n    )\n\n    y_train_cat = to_categorical(y_train_aug, num_classes=3)\n    y_test_cat = to_categorical(y_test, num_classes=3)\n\n    x_train_dict = {'ecg': X_ecg_train_aug, 'eda': X_eda_train_aug, 'resp': X_resp_train_aug}\n    x_test_dict = {'ecg': X_ecg_test, 'eda': X_eda_test, 'resp': X_resp_test}\n\n    model_kfold = build_model_kfold()\n    model_kfold.fit(x_train_dict, y_train_cat, validation_data=(x_test_dict, y_test_cat),\n                    epochs=10, batch_size=32, verbose=0)\n\n    y_pred_prob = model_kfold.predict(x_test_dict)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='macro')\n    auc = roc_auc_score(y_test_cat, y_pred_prob, average='macro', multi_class='ovr')\n\n    results.append([f\"Fold-{fold_idx+1}\", acc, f1, auc])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === T·ªïng h·ª£p k·∫øt qu·∫£ ===\nresults_df = pd.DataFrame(results, columns=[\"Fold\", \"Accuracy\", \"F1_macro\", \"AUC\"])\n\nprint(\" K·∫øt qu·∫£ trung b√¨nh ¬± ƒë·ªô l·ªách chu·∫©n:\")\nfor col in [\"Accuracy\", \"F1_macro\", \"AUC\"]:\n    mean = results_df[col].mean() * 100\n    std = results_df[col].std() * 100\n    print(f\"{col}: {mean:.2f} ¬± {std:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£ t·ª´ng fold\nprint(\" K·∫øt qu·∫£ t·ª´ng fold:\")\nprint(results_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === V·∫Ω boxplot ===\nplt.figure(figsize=(10, 5))\nsns.boxplot(data=results_df[[\"Accuracy\", \"F1_macro\", \"AUC\"]])\nplt.title(\"5-Fold Cross-Subject Performance\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.savefig('/kaggle/working/fold5.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CNN-only 5-fold","metadata":{}},{"cell_type":"code","source":"# === ƒê·ªãnh nghƒ©a h√†m build model ===\ndef build_cnn_model_kfold():\n    model = build_cnn_only_model()\n    alpha_list = [1.0, 1.7, 1.2]\n    loss_fn = FocalLoss(gamma=1.0, alpha=alpha_list)\n    optimizer = AdamW(learning_rate=1e-4, weight_decay=5e-5)\n    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n    return model\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_results = []\n# === V√≤ng l·∫∑p theo t·ª´ng fold ===\nfor fold_idx, (train_subj_idx, test_subj_idx) in enumerate(kf.split(unique_sid)):\n    train_subjects = unique_sid[train_subj_idx]\n    test_subjects = unique_sid[test_subj_idx]\n\n    train_mask = np.isin(sid_clean, train_subjects)\n    test_mask = np.isin(sid_clean, test_subjects)\n\n    X_ecg_train, X_eda_train, X_resp_train = X_ecg[train_mask], X_eda[train_mask], X_resp[train_mask]\n    X_ecg_test, X_eda_test, X_resp_test = X_ecg[test_mask], X_eda[test_mask], X_resp[test_mask]\n    y_train, y_test = y[train_mask], y[test_mask]\n\n    # === Augmentation ===\n    X_ecg_train_aug, X_eda_train_aug, X_resp_train_aug, y_train_aug = augment_train_set(\n        X_ecg_train, X_eda_train, X_resp_train, y_train,\n        use_random=True, seed=42, plot_distribution=False\n    )\n\n    y_train_cat = to_categorical(y_train_aug, num_classes=3)\n    y_test_cat = to_categorical(y_test, num_classes=3)\n\n    x_train_dict = {'ecg': X_ecg_train_aug, 'eda': X_eda_train_aug, 'resp': X_resp_train_aug}\n    x_test_dict = {'ecg': X_ecg_test, 'eda': X_eda_test, 'resp': X_resp_test}\n\n    cnn_model_kfold = build_cnn_model_kfold()\n    cnn_model_kfold.fit(x_train_dict, y_train_cat, validation_data=(x_test_dict, y_test_cat),\n                    epochs=10, batch_size=32, verbose=0)\n\n    y_pred_prob = cnn_model_kfold.predict(x_test_dict)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='macro')\n    auc = roc_auc_score(y_test_cat, y_pred_prob, average='macro', multi_class='ovr')\n\n    cnn_results.append([f\"Fold-{fold_idx+1}\", acc, f1, auc])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === T·ªïng h·ª£p k·∫øt qu·∫£ ===\ncnn_results_df = pd.DataFrame(cnn_results, columns=[\"Fold\", \"Accuracy\", \"F1_macro\", \"AUC\"])\n\nprint(\" K·∫øt qu·∫£ trung b√¨nh ¬± ƒë·ªô l·ªách chu·∫©n:\")\nfor col in [\"Accuracy\", \"F1_macro\", \"AUC\"]:\n    cnn_mean = cnn_results_df[col].mean() * 100\n    cnn_std = cnn_results_df[col].std() * 100\n    print(f\"{col}: {cnn_mean:.2f} ¬± {cnn_std:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£ t·ª´ng fold\nprint(\" K·∫øt qu·∫£ t·ª´ng fold:\")\nprint(cnn_results_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === V·∫Ω boxplot ===\nplt.figure(figsize=(10, 5))\nsns.boxplot(data=cnn_results_df[[\"Accuracy\", \"F1_macro\", \"AUC\"]])\nplt.title(\"5-Fold Cross-Subject Performance\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.savefig('/kaggle/working/fold5_cnn.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### RNN-only 5-fold","metadata":{}},{"cell_type":"code","source":"# === ƒê·ªãnh nghƒ©a h√†m build model ===\ndef build_rnn_model_kfold():\n    model = build_bigru_only_model()\n    alpha_list = [1.0, 1.7, 1.2]\n    loss_fn = FocalLoss(gamma=1.0, alpha=alpha_list)\n    optimizer = AdamW(learning_rate=1e-4, weight_decay=5e-5)\n    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n    return model\n\nprint('‚úîÔ∏è Done!')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rnn_results = []\n# === V√≤ng l·∫∑p theo t·ª´ng fold ===\nfor fold_idx, (train_subj_idx, test_subj_idx) in enumerate(kf.split(unique_sid)):\n    train_subjects = unique_sid[train_subj_idx]\n    test_subjects = unique_sid[test_subj_idx]\n\n    train_mask = np.isin(sid_clean, train_subjects)\n    test_mask = np.isin(sid_clean, test_subjects)\n\n    X_ecg_train, X_eda_train, X_resp_train = X_ecg[train_mask], X_eda[train_mask], X_resp[train_mask]\n    X_ecg_test, X_eda_test, X_resp_test = X_ecg[test_mask], X_eda[test_mask], X_resp[test_mask]\n    y_train, y_test = y[train_mask], y[test_mask]\n\n    # === Augmentation ===\n    X_ecg_train_aug, X_eda_train_aug, X_resp_train_aug, y_train_aug = augment_train_set(\n        X_ecg_train, X_eda_train, X_resp_train, y_train,\n        use_random=True, seed=42, plot_distribution=False\n    )\n\n    y_train_cat = to_categorical(y_train_aug, num_classes=3)\n    y_test_cat = to_categorical(y_test, num_classes=3)\n\n    x_train_dict = {'ecg': X_ecg_train_aug, 'eda': X_eda_train_aug, 'resp': X_resp_train_aug}\n    x_test_dict = {'ecg': X_ecg_test, 'eda': X_eda_test, 'resp': X_resp_test}\n\n    rnn_model_kfold = build_rnn_model_kfold()\n    rnn_model_kfold.fit(x_train_dict, y_train_cat, validation_data=(x_test_dict, y_test_cat),\n                    epochs=10, batch_size=32, verbose=0)\n\n    y_pred_prob = rnn_model_kfold.predict(x_test_dict)\n    y_pred = np.argmax(y_pred_prob, axis=1)\n\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='macro')\n    auc = roc_auc_score(y_test_cat, y_pred_prob, average='macro', multi_class='ovr')\n\n    rnn_results.append([f\"Fold-{fold_idx+1}\", acc, f1, auc])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === T·ªïng h·ª£p k·∫øt qu·∫£ ===\nrnn_results_df = pd.DataFrame(rnn_results, columns=[\"Fold\", \"Accuracy\", \"F1_macro\", \"AUC\"])\n\nprint(\" K·∫øt qu·∫£ trung b√¨nh ¬± ƒë·ªô l·ªách chu·∫©n:\")\nfor col in [\"Accuracy\", \"F1_macro\", \"AUC\"]:\n    rnn_mean = rnn_results_df[col].mean() * 100\n    rnn_std = rnn_results_df[col].std() * 100\n    print(f\"{col}: {rnn_mean:.2f} ¬± {rnn_std:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£ t·ª´ng fold\nprint(\" K·∫øt qu·∫£ t·ª´ng fold:\")\nprint(rnn_results_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === V·∫Ω boxplot ===\nplt.figure(figsize=(10, 5))\nsns.boxplot(data=rnn_results_df[[\"Accuracy\", \"F1_macro\", \"AUC\"]])\nplt.title(\"5-Fold Cross-Subject Performance\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.savefig('/kaggle/working/fold5_rnn.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prepare data for K-Fold machine learning","metadata":{}},{"cell_type":"code","source":"# Tr√≠ch ƒë·∫∑c tr∆∞ng to√†n b·ªô dataset\nX_features = extract_all_features_custom(X_ecg, X_eda, X_resp)\ny_labels = y  # gi·ªØ nguy√™n\n\nclass_names = ['Baseline', 'Stress', 'Amusement']\nn_classes = len(class_names)\n\n# Ki·ªÉm tra chi·ªÅu\nassert X_features.shape[0] == y_labels.shape[0] == sid_clean.shape[0]\nunique_sid = np.unique(sid_clean)\nassert len(unique_sid) % 5 == 0, \"S·ªë subject ph·∫£i chia h·∫øt cho 5 ƒë·ªÉ chia ƒë·ªÅu c√°c fold\"\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SVM 5-fold","metadata":{}},{"cell_type":"code","source":"svm_results = []\n\nfor fold_idx, (train_sid_idx, test_sid_idx) in enumerate(kf.split(unique_sid)):\n    train_sid = unique_sid[train_sid_idx]\n    test_sid = unique_sid[test_sid_idx]\n\n    train_mask = np.isin(sid_clean, train_sid)\n    test_mask = np.isin(sid_clean, test_sid)\n\n    X_train, y_train = X_features[train_mask], y_labels[train_mask]\n    X_test, y_test = X_features[test_mask], y_labels[test_mask]\n\n    # Chu·∫©n h√≥a\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    # Hu·∫•n luy·ªán SVM\n    clf = SVC(kernel='rbf', C=1.0, probability=True, random_state=42)\n    clf.fit(X_train_scaled, y_train)\n\n    # D·ª± ƒëo√°n\n    y_pred = clf.predict(X_test_scaled)\n    y_proba = clf.predict_proba(X_test_scaled)\n    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n\n    # ƒê√°nh gi√°\n    acc = accuracy_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='macro')\n    auc = roc_auc_score(y_test_bin, y_proba, average='macro', multi_class='ovr')\n\n    svm_results.append([f\"Fold-{fold_idx+1}\", acc, f1, auc])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_results_df = pd.DataFrame(svm_results, columns=[\"Fold\", \"Accuracy\", \"F1_macro\", \"AUC\"])\n\nprint(\" K·∫øt qu·∫£ trung b√¨nh ¬± ƒë·ªô l·ªách chu·∫©n:\")\nfor col in [\"Accuracy\", \"F1_macro\", \"AUC\"]:\n    mean = svm_results_df[col].mean() * 100\n    std = svm_results_df[col].std() * 100\n    print(f\"{col}: {mean:.2f} ¬± {std:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n K·∫øt qu·∫£ t·ª´ng fold:\")\nprint(svm_results_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# V·∫Ω boxplot\nplt.figure(figsize=(10, 5))\nsns.boxplot(data=svm_results_df[[\"Accuracy\", \"F1_macro\", \"AUC\"]])\nplt.title(\"5-Fold Cross-Subject Performance (SVM)\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.tight_layout()\nplt.savefig('/kaggle/working/kfold_svm_boxplot.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Random Forest 5-fold","metadata":{}},{"cell_type":"code","source":"rf_results = []\n\n# === V√≤ng l·∫∑p K-Fold ===\nfor fold_idx, (train_sid_idx, test_sid_idx) in enumerate(kf.split(unique_sid)):\n    train_sid = unique_sid[train_sid_idx]\n    test_sid = unique_sid[test_sid_idx]\n\n    train_mask = np.isin(sid_clean, train_sid)\n    test_mask = np.isin(sid_clean, test_sid)\n\n    X_train, y_train = X_features[train_mask], y[train_mask]\n    X_test, y_test = X_features[test_mask], y[test_mask]\n\n    # Chu·∫©n h√≥a\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    # Hu·∫•n luy·ªán m√¥ h√¨nh Random Forest\n    rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf_clf.fit(X_train_scaled, y_train)\n\n    # D·ª± ƒëo√°n\n    y_pred_rf = rf_clf.predict(X_test_scaled)\n    y_proba_rf = rf_clf.predict_proba(X_test_scaled)\n    y_test_bin = label_binarize(y_test, classes=range(n_classes))\n\n    # ƒê√°nh gi√°\n    acc = accuracy_score(y_test, y_pred_rf)\n    f1 = f1_score(y_test, y_pred_rf, average='macro')\n    auc = roc_auc_score(y_test_bin, y_proba_rf, average='macro', multi_class='ovr')\n\n    rf_results.append([f\"Fold-{fold_idx+1}\", acc, f1, auc])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_results_df = pd.DataFrame(rf_results, columns=[\"Fold\", \"Accuracy\", \"F1_macro\", \"AUC\"])\n\nprint(\" K·∫øt qu·∫£ trung b√¨nh ¬± ƒë·ªô l·ªách chu·∫©n (Random Forest):\")\nfor col in [\"Accuracy\", \"F1_macro\", \"AUC\"]:\n    mean = rf_results_df[col].mean() * 100\n    std = rf_results_df[col].std() * 100\n    print(f\"{col}: {mean:.2f} ¬± {std:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n K·∫øt qu·∫£ t·ª´ng fold:\")\nprint(rf_results_df.to_string(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# V·∫Ω boxplot\nplt.figure(figsize=(10, 5))\nsns.boxplot(data=results_rf_df[[\"Accuracy\", \"F1_macro\", \"AUC\"]])\nplt.title(\"5-Fold Cross-Subject Performance (Random Forest)\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.tight_layout()\nplt.savefig('/kaggle/working/kfold_randomforest_boxplot.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}